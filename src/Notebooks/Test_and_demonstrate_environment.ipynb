{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_and_demonstrate_environment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zswRucSMfo1-",
        "colab_type": "code",
        "outputId": "3dd2e22f-70d8-40ff-f82f-7a5b9fb7894f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import: imports\n",
        "directory_path = \"/content/drive/My\\ Drive/Embodied_counting/src/\"\n",
        "\n",
        "file_name = \"imports.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "# Import: environment\n",
        "directory_path = \"/content/drive/My\\ Drive/Embodied_counting/src/environment/\"\n",
        "\n",
        "file_name = \"count_environment.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "!python $PATH\n",
        "\n",
        "file_name = \"solving_algorithms.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "\n",
        "# Import: models\n",
        "directory_path = \"/content/drive/My\\ Drive/Embodied_counting/src/models/\"\n",
        "\n",
        "file_name = \"LangConvLSTM.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "\n",
        "# Import: train_and_test\n",
        "directory_path = \"/content/drive/My\\ Drive/Embodied_counting/src/train_and_test/\"\n",
        "\n",
        "file_name = \"train_model_original.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "file_name = \"test_model.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "file_name = \"demonstrate_model.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "file_name = \"env_to_pytorch_interface.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "\n",
        "# Import: manage_results\n",
        "directory_path = \"/content/drive/My\\ Drive/Embodied_counting/src/manage_results/\"\n",
        "\n",
        "file_name = \"run_schedules.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "file_name = \"save_and_plot.py\"\n",
        "PATH = directory_path + file_name\n",
        "%run -i $PATH\n",
        "\n",
        "CUDA_bool = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Import ...\n",
            "Libraries/Packages successfully imported...\n",
            "Load Count-Environment..!\n",
            "Load Count-Environment..!\n",
            "Loading Automatic Solving Algorithms..\n",
            "Loading model....\n",
            "Load training process..\n",
            "Load test process .... \n",
            "Import demonstrate-model ..\n",
            "Load env-to-pytorch interface .... \n",
            "Load run, schedules ..! \n",
            "Load result managing..!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLkgcz8ld9l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_concat_h(im1, im2):\n",
        "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (im1.width, 0))\n",
        "    return dst\n",
        "\n",
        "def get_concat_v(im1, im2):\n",
        "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (0, im1.height))\n",
        "    return dst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5XFQkwPS-Rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "235d9a6d-a2a6-4960-94c4-6157c64ef3e4"
      },
      "source": [
        "print(env.display)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "game\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5mSuYQGe5I8",
        "colab_type": "code",
        "outputId": "d72ff50b-dda1-4597-bf45-7dcf5afef5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "################################\n",
        "## Demonstrate Counting Environment: Solving algorithm\n",
        "###############################\n",
        "\n",
        "env = CountEnv(mode=\"pick_square\", max_dist = 10, n_squares = 2, display = \"game\", save_epoch = False )\n",
        "env.task = \"count_on\"\n",
        "env.print_sub_tasks_after_steps = True\n",
        "env.print_action_onehot_aftersteps = True\n",
        "env.rand_n_squares = False\n",
        "env.add_n = 3\n",
        "print(env.task)\n",
        "env.reset()\n",
        "\n",
        "env.display = \"None\"\n",
        "#env.solve_task()\n",
        "#demonstrate_model(env, model)\n",
        "#do_nothing(env)\n",
        "env.solve_task()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count_on\n",
            "One-to-one correspondence:  False\n",
            "Right number sequence:  False\n",
            "--------------------------------\n",
            "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1']\n",
            "['D', 'U', 'R', 'L', 'P', 'Dr', 'T', 'A', 'E', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S']\n",
            "--------------------------------\n",
            "One-to-one correspondence:  False\n",
            "Right number sequence:  False\n",
            "--------------------------------\n",
            "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1']\n",
            "['D', 'U', 'R', 'L', 'P', 'Dr', 'T', 'A', 'E', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S']\n",
            "--------------------------------\n",
            "One-to-one correspondence:  False\n",
            "Right number sequence:  False\n",
            "--------------------------------\n",
            "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1']\n",
            "['D', 'U', 'R', 'L', 'P', 'Dr', 'T', 'A', 'E', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S']\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "['0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1']\n",
            "['D', 'U', 'R', 'L', 'P', 'Dr', 'T', 'A', 'E', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S']\n",
            "--------------------------------\n",
            "One-to-one correspondence:  False\n",
            "Right number sequence:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guZO4oDgqNfK",
        "colab_type": "code",
        "outputId": "7608c754-5b53-4384-ec1a-2763f1e26d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "print(\"Load Count-Environment....\")\n",
        "\n",
        "class Square():\n",
        "  def __init__(self, pos, id_, n_neighbours):\n",
        "    self.pos = pos\n",
        "    self.id = id_\n",
        "    self.n_neighbours = n_neighbours\n",
        "    self.update_obs()\n",
        "    \n",
        "    self.picked_already = False \n",
        "    self.touched_already = False \n",
        "    self.touched_count = 0\n",
        "    \n",
        "    \n",
        "  def update_obs(self):\n",
        "    self.data = np.ones((1, 1), dtype=np.uint8)*255\n",
        "    self.obj_belong_fct = np.zeros((2*self.n_neighbours, 2*self.n_neighbours), dtype=np.uint8)\n",
        "    \n",
        "\n",
        "    \n",
        "  def move(self, direction):\n",
        "    move_dist=1\n",
        "    \n",
        "    if(direction==\"right\"):\n",
        "      self.pos.x += move_dist\n",
        "    elif(direction==\"left\"):\n",
        "      self.pos.x -= move_dist\n",
        "    elif(direction==\"up\"):\n",
        "      self.pos.y += move_dist\n",
        "    elif(direction==\"down\"):\n",
        "      self.pos.y -= move_dist\n",
        "      \n",
        "    self.update_obs()\n",
        "\n",
        "class Hand():\n",
        "    def __init__(self, data,data_mask, pos):\n",
        "      self.data = data\n",
        "      self.pos = pos\n",
        "      self.data_mask = data_mask\n",
        "      \n",
        "\n",
        "class Pos():\n",
        "  def __init__(self, x_, y_):\n",
        "    self.x = x_\n",
        "    self.y = y_\n",
        "  \n",
        "  \n",
        "class CountEnv():\n",
        "    def __init__(self,task_ = \"touch_all_objects\", mode=\"pick_square\", max_dist = 20, n_squares = 1, display = \"None\", save_epoch = False, img_size = 4, obj_source=\"squares\"):\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.view_size = img_size\n",
        "        self.mode = mode\n",
        "        self.n_squares_max = n_squares\n",
        "        self.max_dist = max_dist\n",
        "        self.task = task_   # move_all_squares_from_source_to_target / touch_all_objects\n",
        "        \n",
        "        self.count_action = False\n",
        "        self.motor_action = False\n",
        "        self.since_count_action = 0\n",
        "        self.show_number_length = 1\n",
        "        self.show_number = False\n",
        "        self.last_count_number = 0\n",
        "        self.rand_n_squares=True\n",
        "        \n",
        "        self.IsTripleAction = False\n",
        "        self.action_motor = \"\"\n",
        "        self.action_IsSayWord = True\n",
        "        self.action_word = \"\"\n",
        "        \n",
        "        self.counted_word_list = [] \n",
        "        self.aimed_count_list = []\n",
        "        self.counted_square_list = []\n",
        "        self.aimed_given_square_id_list = []\n",
        "        self.given_square_id_list = []\n",
        "        \n",
        "        self.sample_task = False\n",
        "        self.task_list = None\n",
        "        self.observation_hand = []\n",
        "        self.observation_square = []\n",
        "        \n",
        "        self.n_squares_max_list = [self.n_squares_max]*10\n",
        "        self.n_squares_wished = -1\n",
        "        self.active_context = 1\n",
        "        self.active_object = 2\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        self.reset()\n",
        "        \n",
        "        self.n_motor_actions = 7\n",
        "        self.n_words = 10\n",
        "        \n",
        "        self.n_actions = self.n_motor_actions + self.n_words + 2\n",
        "        self.action = 1\n",
        "        self.action_onehot = np.array([int(i == 0) for i in range(self.n_actions)])\n",
        "        self.total_reward = 0\n",
        "        self.display = display\n",
        "        self.save_epoch = save_epoch\n",
        "        self.relations = []\n",
        "        \n",
        "        self.move_dist = 1\n",
        "\n",
        "        \n",
        "        self.task_vector_length = 20\n",
        "        self.obj_source = obj_source\n",
        "        \n",
        "        self.pick_from_00 = False\n",
        "        self.pick_from_00_then_move = False\n",
        "        self.give_n_current_squares = 1\n",
        "        self.readable_action_onehot = []\n",
        "        \n",
        "        self.print_action_onehot_aftersteps = False\n",
        "        self.print_sub_tasks_after_steps = False\n",
        "        \n",
        "        \n",
        "\n",
        "            \n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "    def reset(self):\n",
        "      \n",
        "        self.time = 0\n",
        "        self.ended = False\n",
        "        self.total_reward = 0\n",
        "        self.picked = False\n",
        "        self.time_penalty = 0.02\n",
        "        self.epoch = []\n",
        "        self.IsTripleAction = False\n",
        "        self.hand_is_visible = True\n",
        "        self.square_is_visible = True\n",
        "        self.second_action = True\n",
        "        self.since_last_event_count = 1\n",
        "        self.event_had_occured_already = False\n",
        "        self.last_action_is_count = True\n",
        "        self.steps_after_given_square = 2\n",
        "        \n",
        "        self.n_wait_steps = random.randint(1,5)\n",
        "        self.last_event_count = 0\n",
        "        self.stopped_early = False\n",
        "        self.one_step_after_event = False\n",
        "        \n",
        "        self.one_to_one_correspondence = False\n",
        "        self.right_number_order = False\n",
        "        self.variability = 0.0\n",
        "        \n",
        "        self.missed_count = False\n",
        "        self.counted_none_object = False\n",
        "         \n",
        "        \n",
        "        if(self.sample_task==True):\n",
        "            self.task = random.sample(self.task_list,1)[0]  \n",
        "        \n",
        "        if(self.task_list is None):\n",
        "          self.task_n = 0\n",
        "        else:\n",
        "          self.task_n = self.task_list.index(self.task)\n",
        "            \n",
        "            \n",
        "        if(self.rand_n_squares==True):\n",
        "            self.n_squares = random.randint(1,self.n_squares_max)\n",
        "            self.n_squares = random.randint(1,self.n_squares_max_list[self.task_n])\n",
        "        else:\n",
        "            self.n_squares = self.n_squares_max\n",
        "        \n",
        "        if(self.rand_n_squares==True and self.sample_task==True):\n",
        "            self.n_squares = random.randint(1,self.n_squares_max_list[self.task_n])\n",
        "\n",
        "        if(self.n_squares_wished >= 0):\n",
        "            self.n_squares = self.n_squares_wished\n",
        "        \n",
        "        self.task_n = 0\n",
        "        \n",
        "        self.counted_word_list = [] \n",
        "        self.aimed_count_list = []\n",
        "        self.counted_square_list = []\n",
        "        self.given_square_id_list = []\n",
        "        self.aimed_given_square_id_list = []\n",
        "        \n",
        "        for i in range(self.n_squares):\n",
        "            self.aimed_count_list.append(str(i+1) )\n",
        "            #self.aimed_count_list.append(str(self.n_squares - i) )\n",
        "            self.aimed_given_square_id_list.append(str(i+1) )\n",
        "            \n",
        "\n",
        "\n",
        "        self.max_time = 100\n",
        "        ## Task encoding: task, object and quantifier to integer\n",
        "        if(self.task == 'touch_all_objects'):\n",
        "            self.task_n = 0\n",
        "            self.object_n = 0\n",
        "            self.quant_n = 0\n",
        "            self.max_time = self.n_squares*10\n",
        "        #elif(self.task == 'move_all_squares_from_source_to_target'):\n",
        "        #    self.task_n = 1\n",
        "        #    self.object_n = 0\n",
        "        #    self.quant_n = 0\n",
        "        elif(self.task == 'count_all_objects'):\n",
        "            self.task_n = 1\n",
        "            self.object_n = 0\n",
        "            self.quant_n = 0\n",
        "            self.max_time = self.n_squares*10\n",
        "        elif(self.task == 'count_all_events'):\n",
        "            self.task_n = 1\n",
        "            self.object_n = 1\n",
        "            self.quant_n = 0\n",
        "            self.hand_is_visible = False\n",
        "            self.max_time = self.n_squares*8\n",
        "            \n",
        "        elif(self.task == 'count_all_events_1'):\n",
        "            self.task_n = 0\n",
        "            self.object_n = 1\n",
        "            self.quant_n = 0\n",
        "            self.hand_is_visible = False\n",
        "            self.max_time = self.n_squares*8\n",
        "\n",
        "        elif(self.task == 'count_all_events_2'):\n",
        "            self.task_n = 1\n",
        "            self.object_n = 1\n",
        "            self.quant_n = 0\n",
        "            self.hand_is_visible = False\n",
        "            self.max_time = self.n_squares*8            \n",
        "            \n",
        "        elif(self.task == 'give_n'):\n",
        "            self.task_n = 2\n",
        "            self.object_n = 0\n",
        "            self.quant_n = self.n_squares  \n",
        "            self.max_time = self.n_squares*9 + 6  \n",
        "                        \n",
        "        elif(self.task == 'recite_n'):\n",
        "            self.task_n = 3\n",
        "            self.object_n = 0\n",
        "            self.quant_n = self.n_squares\n",
        "            self.hand_is_visible = False\n",
        "            self.square_is_visible = False\n",
        "            self.max_time = self.n_squares*2\n",
        "            \n",
        "        elif(self.task == 'do_nothing'):\n",
        "            self.task_n = 4\n",
        "            self.object_n = 1\n",
        "            self.quant_n = 0\n",
        "            self.hand_is_visible = False\n",
        "            self.square_is_visible = False\n",
        "            self.max_time = self.n_squares*2\n",
        "            self.did_nothing = True\n",
        "\n",
        "        elif(self.task == 'recite_n_inverse'):\n",
        "            self.task_n = 5\n",
        "            self.object_n = 0\n",
        "            self.quant_n = self.n_squares\n",
        "            self.hand_is_visible = False\n",
        "            self.square_is_visible = False\n",
        "            self.max_time = self.n_squares*2\n",
        "            for i in range(self.n_squares):\n",
        "               self.aimed_count_list.append(str(self.n_squares-i) )\n",
        "           \n",
        "        \n",
        "            \n",
        "\n",
        "            \n",
        "        background = np.zeros([self.img_size,1])\n",
        "        \n",
        "                \n",
        "        self.background = background\n",
        "        \n",
        "        \n",
        "        pnt_size = 1\n",
        "        \n",
        "        pointer, pointer_mask = np.array([[255]]), np.array([[255]])\n",
        "        pointer_grab, _ = np.array([[255]]), np.array([[255]])\n",
        "\n",
        "        hand_pos_x = random.randint(0,self.img_size-1) \n",
        "        hand_pos_y = random.randint(0,self.img_size-1) \n",
        "        pos = Pos(hand_pos_x, hand_pos_y)\n",
        "        hand = Hand(pointer,pointer_mask, pos)\n",
        "        hand_grab = Hand(pointer_grab,pointer_mask, pos)\n",
        "        \n",
        "        squares = [] #Create_N_Sqaures(self.n_squares, mode = self.mode, max_dist = self.max_dist, img_size = self.img_size)\n",
        "        pos_list = []\n",
        "        for n in range(self.n_squares):\n",
        "            \n",
        "            pos_not_ok = True\n",
        "            rand_pixel_1 = random.randint(0,self.img_size-1) \n",
        "            rand_pixel_2 = random.randint(0,self.img_size-1) \n",
        "            \n",
        "            while(pos_not_ok):\n",
        "                rand_pixel_1 = random.randint(0,self.img_size-1) \n",
        "                rand_pixel_2 = random.randint(0,self.img_size-1) \n",
        "                pos_array = np.array([rand_pixel_1, rand_pixel_2])\n",
        "                \n",
        "                if(any((pos_array == x).all() for x in pos_list)):\n",
        "                    pos_not_ok = True\n",
        "                else:\n",
        "                    pos_not_ok = False\n",
        "                    pos_list.append(pos_array)\n",
        "                                      \n",
        "            pos = Pos(rand_pixel_1, rand_pixel_2)\n",
        "            square_now = Square(pos, n+1, 0 )  #data, pos, id_, n_neighbours\n",
        "            squares.append(square_now)\n",
        "        \n",
        "        if(self.task == \"give_n\"):\n",
        "            self.squares = []\n",
        "            pos = Pos(0, 0)\n",
        "            square_now = Square(pos, 1, 0 )  #data, pos, id_, n_neighbours\n",
        "            self.squares.append(square_now)\n",
        "            self.obj_source = \"infinite_squares\"\n",
        "            #self.squares = squares\n",
        "        else:\n",
        "            self.squares = squares\n",
        "        \n",
        "        if(self.task==\"count_all_events\"):\n",
        "            self.squares = []\n",
        "            pos = Pos(3, 3)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "            self.event_there = False\n",
        "            self.square_is_visible = False\n",
        "        \n",
        "        if(self.task==\"count_all_events_1\"):\n",
        "            self.squares = []\n",
        "            pos = Pos(3, 3)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "            self.event_there = False\n",
        "            \n",
        "            self.active_context = 0\n",
        "            print(\"self.active_object = 2\")\n",
        "            self.active_object = 2\n",
        "            self.square_is_visible = False\n",
        "        if(self.task==\"count_all_events_2\"):\n",
        "            self.squares = []\n",
        "            pos = Pos(3, 3)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "            self.event_there = False\n",
        "            \n",
        "            self.active_context = 1\n",
        "            self.active_object = 3\n",
        "            self.square_is_visible = False\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.hand = hand        \n",
        "        self.hand_nongrab = copy(hand)\n",
        "        self.hand_grab = copy(hand_grab)\n",
        "        \n",
        "        self.visObs, self.observation, self.obj_belong_fct = self.constructObs()\n",
        "        #print(\"self.obj_belong_fct: \", self.obj_belong_fct)\n",
        "        self.IsGrab = False\n",
        "        self.IsTouch = False\n",
        "        \n",
        "        self.grabed_square = 0\n",
        "        \n",
        "        self.reward = 0\n",
        "        self.picked_once_already = False\n",
        "        self.been_right_already = False\n",
        "        self.is_done = False\n",
        "        #display(Image.fromarray(hand.data) )\n",
        "        #display(Image.fromarray(hand_grab.data) )\n",
        "        self.pick_from_00 = False\n",
        "        self.pick_from_00_then_move = False\n",
        "        self.give_n_current_squares = 1\n",
        "        \n",
        "        \n",
        "    def constructObs(self):\n",
        "            \n",
        "        # Array\n",
        "        self.observation = copy(self.background)\n",
        "        self.observation_hand = copy(self.background)\n",
        "        self.observation_square = copy(self.background)\n",
        "        self.obj_belong_fct = np.zeros([self.img_size,self.img_size]).astype(int) #copy(self.background).astype(int)\n",
        "\n",
        "        self.observation[self.active_context, 0] = 255\n",
        "        if(self.square_is_visible == True):\n",
        "            self.observation[self.active_object, 0] = 255\n",
        "        \n",
        "        \n",
        "        #print(\"self.obj_belong_fct: \", self.obj_belong_fct )\n",
        "\n",
        "        observation_copy = copy(self.observation)        \n",
        "        #self.observationImg.paste(hand_img, (self.hand.pos.x, self.hand.pos.y), hand_mask)\n",
        "        self.observationImg = Image.fromarray(observation_copy)\n",
        "        self.observationImg = self.observationImg.resize( (100,400))\n",
        "        \n",
        "                #### Count window\n",
        "        if(self.show_number == True):\n",
        "            count_window_size = 8\n",
        "            intensity_factor = 1 # np.sin(self.since_count_action/self.show_number_length*np.pi)\n",
        "            count_window = create_count_window(count_window_size, n=self.last_count_number )*intensity_factor\n",
        "            count_window = Image.fromarray(count_window).resize((50,50)).convert('RGB')\n",
        "            bord_dist = int(self.img_size/20)       \n",
        "            #observation_copy[bord_dist:count_window_size+bord_dist, self.img_size - count_window_size - bord_dist:self.img_size-bord_dist] = count_window\n",
        "            #self.observation[bord_dist:count_window_size+bord_dist, self.img_size - count_window_size - bord_dist:self.img_size-bord_dist] = count_window \n",
        "            bg_w, bg_h = self.observationImg.size\n",
        "            img_w, img_h = count_window.size\n",
        "            offset = ((bg_w - img_w) // 2, (bg_h - img_h) // 2)\n",
        "            if(self.task == \"count_all_events\"):\n",
        "              offset = ((bg_w - img_w) // 12, (bg_h - img_h) // 12)\n",
        "            self.observationImg.paste(count_window, offset)\n",
        "        \n",
        "        return self.observationImg, self.observation, self.obj_belong_fct\n",
        "      \n",
        "    def solve_task(self):\n",
        "                 \n",
        "          if(self.task == \"touch_all_objects\"):\n",
        "              touch_all_objects(self)\n",
        "              \n",
        "          if(self.task == \"count_all_objects\"):\n",
        "              count_all_objects(self)              \n",
        "          if(self.task == \"move_all_squares_from_source_to_target\"):\n",
        "              move_all_squares_from_source_to_target(self)\n",
        "          if(self.task == \"give_n\"):\n",
        "              give_n(self) \n",
        "          if(self.task == \"count_all_events\"):\n",
        "              count_all_events(self) \n",
        "          if(self.task == \"count_all_events_1\"):\n",
        "              count_all_events(self) \n",
        "          if(self.task == \"count_all_events_2\"):\n",
        "              count_all_events(self) \n",
        "          if(self.task == \"recite_n\"):\n",
        "              recite_n(self)  \n",
        "          if(self.task == \"do_nothing\"):\n",
        "              do_nothing(self)    \n",
        "          if(self.task == \"recite_n_inverse\"):\n",
        "              recite_n_inverse(self)    \n",
        "              \n",
        "    def print_actions(self):\n",
        "        a = self.action_onehot.astype(int).astype(str).tolist()\n",
        "        b = self.a_strings[0]\n",
        "        \n",
        "        print(\"--------------------------------\")\n",
        "        print(a)\n",
        "        print(b)\n",
        "        print(\"--------------------------------\")\n",
        "        \n",
        "    def readable_actionstring(self):\n",
        "        a = self.action_onehot.astype(int).astype(str).tolist()\n",
        "        b = self.a_strings[0]\n",
        "        \n",
        "        readable_actionstring = str(a) + \"\\n\" + str(b)\n",
        "\n",
        "        return readable_actionstring\n",
        "    \n",
        "    def triple_action_one_hot(self, action_motor,IsDoMotorAction,action_word, action_IsSayWord):\n",
        "        action_onehot = np.zeros(self.n_actions)\n",
        "        \n",
        "        \n",
        "        if(IsDoMotorAction==True):  \n",
        "            action_onehot[Action_inv[action_motor]] = 1\n",
        "            #print(\"Action_inv[action_motor]: \", Action_inv[action_motor])\n",
        "            #action_onehot[-2] = 1\n",
        "            action_onehot[self.n_motor_actions] = 1\n",
        "        \n",
        "        \n",
        "        if(action_IsSayWord):\n",
        "            action_onehot[Action_inv[action_word]+1] = 1\n",
        "            #action_onehot[0] = 1  #\"+1\" because Is_Action sneaks in into onehot\n",
        "            action_onehot[-1] = 1\n",
        "\n",
        "            \n",
        "        self.a_strings = [[\"D\", \"U\", \"R\", \"L\", \"P\", \"Dr\", \"T\",\"A\", \"E\", \"1\", \"2\", \"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"S\"]]\n",
        "        self.readable_action_onehot = np.vstack((action_onehot.astype(str),np.asarray(self.a_strings,str)))\n",
        "        \n",
        "\n",
        "            \n",
        "        return action_onehot\n",
        "              \n",
        "    def triple_update(self, action_motor, IsDoMotorAction, word, IsSayWord):\n",
        "\n",
        "\n",
        "              \n",
        "        # If input was string convert to int\n",
        "        if(type(action_motor)==int):\n",
        "            action_motor = Action[action_motor]\n",
        "        else:\n",
        "            action_motor = action_motor\n",
        "            \n",
        "        if(type(word)==int):\n",
        "            word = Action[word]\n",
        "        else:\n",
        "            word = word\n",
        "      \n",
        "        # Globalize to instance variables\n",
        "        self.action_motor = action_motor\n",
        "        self.action_IsSayWord = IsSayWord\n",
        "        self.IsSayWord = IsSayWord\n",
        "        self.IsDoMotorAction = IsDoMotorAction\n",
        "        self.action_word = word\n",
        "        \n",
        "        self.IsTripleAction = True\n",
        "        \n",
        "        self.second_action = False\n",
        "        \n",
        "        if(IsDoMotorAction):\n",
        "          if(IsSayWord == False):\n",
        "              self.second_action = True\n",
        "          self.update(action_motor)\n",
        "        \n",
        "        self.observationImg_between = self.observationImg\n",
        "        \n",
        "        self.second_action = True\n",
        "        if(IsSayWord):\n",
        "            self.update(word)\n",
        "        '''    \n",
        "        # COUNT ALL EVENTS      \n",
        "        if(self.task==\"count_all_events\" and self.second_action == True):        \n",
        "          self.last_event_count+=1\n",
        "        \n",
        "          if(self.last_event_count>self.n_wait_steps):\n",
        "            self.event_there = True  \n",
        "            self.event_had_occured_already = True\n",
        "            self.n_wait_steps = random.randint(1,5)\n",
        "            self.last_event_count = 0\n",
        "            self.square_is_visible = True\n",
        "\n",
        "            self.squares = []\n",
        "            pos = Pos(1, 1)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "\n",
        "            pos = Pos(2, 1)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "\n",
        "            pos = Pos(1, 2)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        "\n",
        "            pos = Pos(2, 2)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square)\n",
        " \n",
        "          else:\n",
        "            self.square_is_visible = False\n",
        "            self.squares = []\n",
        "            pos = Pos(3, 3)\n",
        "            new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "            self.squares.append(new_square) \n",
        "            self.event_there = False\n",
        "            \n",
        "          self.since_last_event_count = self.last_event_count\n",
        "          self.one_step_after_event = False\n",
        "          if(self.last_event_count == 1 and self.event_had_occured_already == True):\n",
        "            self.one_step_after_event = True          \n",
        "        '''\n",
        "        \n",
        "        self.action_onehot = self.triple_action_one_hot(self.action_motor, self.IsDoMotorAction, self.action_word, self.IsSayWord)\n",
        "        #action_motor,IsDoMotorAction,action_word, action_IsSayWord)\n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "              \n",
        "        self.IsTripleAction = False\n",
        "        self.IsTouch = False\n",
        "        \n",
        "        if(self.print_action_onehot_aftersteps):\n",
        "          self.print_actions()\n",
        "\n",
        "        if(self.save_epoch):\n",
        "            img, action = envImageAndActionToPytorchFormat(self)\n",
        "            object_features = get_object_features(self)\n",
        "            dual_relations = get_dual_relations_from_features(object_features).float()\n",
        "            self.relations = dual_relations\n",
        "            action_string = self.readable_actionstring()\n",
        "            curr_exp = {'img': img, 'action': action, 'rel': dual_relations, 'dem_img': self.observationImg, 'action_string': action_string}\n",
        "            self.epoch.append(curr_exp)\n",
        "            \n",
        "        self.visObs = self.constructObs()\n",
        "        \n",
        "        \n",
        "        #Turn this on if you want to save the last frame in save_epoch as well for demonstration or anything\n",
        "\n",
        "        if(self.save_epoch and self.ended):\n",
        "            img, action = envImageAndActionToPytorchFormat(self)\n",
        "            object_features = get_object_features(self)\n",
        "            dual_relations = get_dual_relations_from_features(object_features).float()\n",
        "            self.relations = dual_relations\n",
        "            action_string = self.readable_actionstring()\n",
        "            curr_exp = {'img': img, 'action': action, 'rel': dual_relations, 'dem_img': self.observationImg, 'action_string': action_string}\n",
        "            self.epoch.append(curr_exp)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def update(self, action):\n",
        "      \n",
        "      \n",
        "      \n",
        "      #if(self.time > 20):\n",
        "        #self.ended = True\n",
        "        \n",
        "      \n",
        "      \n",
        "      self.reward = 0\n",
        "      \n",
        "      move_dist=self.move_dist\n",
        "      \n",
        "      if(type(action)==int):\n",
        "        self.action = Action[action]\n",
        "      else:\n",
        "        self.action = action\n",
        "      \n",
        "      \n",
        "      \n",
        "      if(Action_inv[self.action]>7 and Action_inv[self.action]<19):\n",
        "          self.action_onehot = np.array([int(i == Action_inv[self.action]) for i in range(self.n_actions)])\n",
        "          self.count_action = True\n",
        "          self.since_count_action = 0\n",
        "          self.show_number = True\n",
        "          self.last_count_number = int(self.action)\n",
        "          self.motor_action = False\n",
        "\n",
        "      else:\n",
        "          self.count_action = False\n",
        "          self.motor_action = True\n",
        "      \n",
        "      if(Action_inv[self.action]==4):\n",
        "          #self.count_action = True\n",
        "          self.since_count_action = 0\n",
        "          self.show_number = True\n",
        "          self.last_count_number = 10     \n",
        "      if(Action_inv[self.action]==5):\n",
        "          #self.count_action = True\n",
        "          self.since_count_action = 0\n",
        "          self.show_number = True\n",
        "          self.last_count_number = 11  \n",
        "          \n",
        "      if(Action_inv[self.action]==6):\n",
        "          #self.count_action = True\n",
        "          self.since_count_action = 0\n",
        "          self.show_number = True\n",
        "          self.last_count_number = 12 \n",
        "          \n",
        "      if(Action_inv[self.action]==7):\n",
        "          #self.count_action = True\n",
        "          self.since_count_action = 0\n",
        "          self.show_number = True\n",
        "          self.last_count_number = 13 \n",
        "          \n",
        "      if(self.since_count_action < self.show_number_length):\n",
        "          self.since_count_action += 1\n",
        "      else: \n",
        "          self.show_number = False\n",
        "      #print(\"incoming action int: \", action)\n",
        "      #print(\"working internally with action: \", self.action)\n",
        "      \n",
        "\n",
        "      \n",
        "      \n",
        "      #################\n",
        "      ## ACTIONS\n",
        "      #################\n",
        "      \n",
        "      if(self.action==\"down\"):\n",
        "        self.action_onehot = np.array([int(i == 0) for i in range(self.n_actions)])\n",
        "        \n",
        "        actual_move_distance = 0\n",
        "        if(self.hand.pos.x<self.img_size-1):\n",
        "          actual_move_distance = move_dist\n",
        "          \n",
        "        # Move hand and object (if grabbed) by actual_move_distance\n",
        "        self.hand.pos.x += actual_move_distance                \n",
        "        if(self.IsGrab == True):\n",
        "          self.squares[self.grabed_square-1].pos.x += actual_move_distance\n",
        "        \n",
        "        \n",
        "      elif(self.action==\"up\"):\n",
        "        self.action_onehot = np.array([int(i == 1) for i in range(self.n_actions)])\n",
        "        \n",
        "        actual_move_distance = 0\n",
        "        if(self.hand.pos.x>0):\n",
        "          actual_move_distance = move_dist\n",
        "          \n",
        "        self.hand.pos.x -= actual_move_distance\n",
        "        if(self.IsGrab == True):\n",
        "          self.squares[self.grabed_square-1].pos.x -= actual_move_distance\n",
        "          \n",
        "      elif(self.action==\"right\"):\n",
        "        self.action_onehot = np.array([int(i == 2) for i in range(self.n_actions)])\n",
        "              \n",
        "        actual_move_distance = 0\n",
        "        if(self.hand.pos.y<self.img_size-1):\n",
        "          actual_move_distance = move_dist\n",
        "          \n",
        "        self.hand.pos.y += actual_move_distance\n",
        "        if(self.IsGrab == True):\n",
        "          self.squares[self.grabed_square-1].pos.y += actual_move_distance\n",
        "          \n",
        "          \n",
        "      elif(self.action==\"left\"):\n",
        "        self.action_onehot = np.array([int(i == 3) for i in range(self.n_actions)])\n",
        "                \n",
        "        actual_move_distance = 0\n",
        "        if(self.hand.pos.y>0):\n",
        "          actual_move_distance = move_dist\n",
        "          \n",
        "        self.hand.pos.y -= actual_move_distance\n",
        "        if(self.IsGrab == True):\n",
        "          self.squares[self.grabed_square-1].pos.y -= actual_move_distance\n",
        "          \n",
        "          \n",
        "      elif(self.action==\"pick\"):\n",
        "        self.action_onehot = np.array([int(i == 4) for i in range(self.n_actions)])\n",
        "        #print(\"self.obj_belong_fct[self.hand.pos.x, self.hand.pos.y] \", self.obj_belong_fct[self.squares[0].pos.x+1, self.squares[0].pos.y+1])\n",
        "        if(self.obj_belong_fct[self.hand.pos.x, self.hand.pos.y] != 0):\n",
        "          self.grabed_square = self.obj_belong_fct[self.hand.pos.x, self.hand.pos.y]\n",
        "          #print(\"grabed square \", self.grabed_square)\n",
        "          self.IsGrab = True\n",
        "          self.hand.data = copy(self.hand_grab.data)\n",
        "          self.squares[self.grabed_square-1].picked_already = True\n",
        "          if(self.hand.pos.x == 0 and self.hand.pos.y==0):\n",
        "            self.pick_from_00 = True\n",
        "          \n",
        "\n",
        "          if(self.picked_once_already == False):\n",
        "            \n",
        "            self.picked = True\n",
        "            self.time_penalty = 0.0\n",
        "          self.picked_once_already = True\n",
        "        \n",
        "      elif(self.action==\"release\"):\n",
        "        self.action_onehot = np.array([int(i == 5) for i in range(self.n_actions)])\n",
        "        if(self.IsGrab):\n",
        "          if(self.hand.pos.y > int(self.img_size/2) ):\n",
        "            #self.reward += 1.0\n",
        "            self.is_done = True\n",
        "        if(self.IsGrab==True and self.hand.pos.y == self.img_size-1):\n",
        "            self.given_square_id_list.append(str(self.grabed_square) )\n",
        "            self.steps_after_given_square = 0\n",
        "            \n",
        "        self.IsGrab = False  \n",
        "        self.hand.data = copy(self.hand_nongrab.data)\n",
        "       \n",
        "      elif(self.action==\"touch\"):     \n",
        "          self.action_onehot = np.array([int(i == 6) for i in range(self.n_actions)])\n",
        "        \n",
        "          if(self.obj_belong_fct[self.hand.pos.x + int(self.hand.data.shape[0]/2), self.hand.pos.y + int(self.hand.data.shape[1]/2)] != 0):\n",
        "              self.touched_square = self.obj_belong_fct[self.hand.pos.x + int(self.hand.data.shape[0]/2), self.hand.pos.y + int(self.hand.data.shape[1]/2)]\n",
        "              self.IsTouch = True\n",
        "              self.hand.data = copy(self.hand_grab.data)\n",
        "              self.squares[self.touched_square-1].touched_already = True\n",
        "              self.squares[self.touched_square-1].touched_count += 1\n",
        "          if(self.obj_belong_fct[self.hand.pos.x + int(self.hand.data.shape[0]/2), self.hand.pos.y + int(self.hand.data.shape[1]/2)] == 0):   \n",
        "              self.counted_none_object = True\n",
        "              \n",
        "      elif(self.action==\"stop\"):     \n",
        "        self.action_onehot = np.array([int(i == 7) for i in range(self.n_actions)])\n",
        "        \n",
        "      if(self.task == \"give_n\"):   \n",
        "          if(Action_inv[self.action]>self.n_motor_actions and Action_inv[self.action]<17):\n",
        "            self.counted_word_list.append(self.action)\n",
        "          if(self.action == \"stop\"):\n",
        "              if(self.given_square_id_list != self.aimed_given_square_id_list or self.counted_word_list!=self.aimed_count_list): \n",
        "                 self.stopped_early = True\n",
        "          if(self.counted_word_list==self.aimed_count_list):\n",
        "             self.right_number_order = True\n",
        "          if(self.given_square_id_list == self.aimed_given_square_id_list and self.counted_word_list==self.aimed_count_list and self.action==\"stop\" and self.stopped_early == False): \n",
        "              self.ended = True\n",
        "        \n",
        "      ######################\n",
        "      ## Create action_onehot\n",
        "      ######################+\n",
        "      \n",
        "      if(self.IsTripleAction == False):\n",
        "        self.IsDoMotorAction = False\n",
        "        self.IsSayWord = False\n",
        "      \n",
        "      # Find out if action is motor action \n",
        "      if(Action_inv[self.action]<self.n_motor_actions):\n",
        "          #self.action_onehot[self.n_motor_actions] = 1\n",
        "          self.IsDoMotorAction = True\n",
        "          \n",
        "       \n",
        "      #Find out if action is saying word\n",
        "      if(Action_inv[self.action]>self.n_motor_actions-1):\n",
        "          #self.action_onehot[self.n_motor_actions] = 1\n",
        "          \n",
        "          self.IsSayWord = True\n",
        "          \n",
        "          \n",
        "      self.action_onehot = self.triple_action_one_hot(self.action, self.IsDoMotorAction, self.action, self.IsSayWord)\n",
        "      if(self.print_action_onehot_aftersteps and self.IsTripleAction==False):\n",
        "          self.print_actions()\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      ### For RL --> rewards\n",
        "      self.reward -= self.time_penalty\n",
        "      self.total_reward += self.reward\n",
        "      \n",
        "      \n",
        "\n",
        "    \n",
        "    \n",
        "      ##################\n",
        "      ## UPDATE ENVIRONMENT\n",
        "      #####################\n",
        "      \n",
        "      # GIVE-N\n",
        "      if( int(self.action == Action_inv[self.action]) < 4 and self.pick_from_00 == True and self.obj_source == \"infinite_squares\"):\n",
        "          pos = Pos(0, 0)\n",
        "          self.give_n_current_squares += 1\n",
        "          new_square = Square(pos, self.give_n_current_squares, 0 )  #(data,) pos, id_, n_neighbours\n",
        "          self.squares.append(new_square)\n",
        "          self.pick_from_00 = False\n",
        "      \n",
        "      if( self.pick_from_00==True and self.action == \"release\"):\n",
        "          self.pick_from_00 = False\n",
        "       \n",
        "\n",
        "      \n",
        "      # COUNT ALL EVENTS     \n",
        "      if(self.task==\"count_all_events_1\" or self.task==\"count_all_events_2\"):\n",
        "        \n",
        "        if(self.second_action == True):        \n",
        "          self.last_event_count+=1\n",
        "\n",
        "          self.last_event_count==1\n",
        "\n",
        "          if(self.last_event_count>self.n_wait_steps):\n",
        "              self.event_there = True  \n",
        "              self.event_had_occured_already = True\n",
        "              self.n_wait_steps = random.randint(1,5)\n",
        "              self.last_event_count = 0\n",
        "              self.square_is_visible = True\n",
        "\n",
        "\n",
        "          else:\n",
        "              self.square_is_visible = False\n",
        "              self.squares = []\n",
        "              pos = Pos(3, 3)\n",
        "              new_square = Square(pos, 0, 0 )  #(data,) pos, id_, n_neighbours\n",
        "              self.squares.append(new_square) \n",
        "              self.event_there = False\n",
        "\n",
        "          self.since_last_event_count = self.last_event_count\n",
        "          self.one_step_after_event = False\n",
        "          if(self.last_event_count == 1 and self.event_had_occured_already == True):\n",
        "              self.one_step_after_event = True\n",
        "        \n",
        "        \n",
        "        \n",
        "      ###########################\n",
        "      ### SET END CONDITIONS\n",
        "      ###########################\n",
        "     \n",
        "      if(self.task == \"give_n\"):\n",
        "            #if(self.steps_after_given_square == 1):\n",
        "          if(self.steps_after_given_square == 1):\n",
        "              if(self.count_action==False):\n",
        "                  self.missed_count = True\n",
        "          if(self.count_action==True):\n",
        "              if(self.steps_after_given_square != 1):\n",
        "                  self.counted_none_object = True\n",
        "            \n",
        "          if(self.missed_count == False and self.counted_none_object == False):\n",
        "              self.one_to_one_correspondence = True\n",
        "          else:\n",
        "              self.one_to_one_correspondence = False\n",
        "            \n",
        "          if(self.second_action == True): \n",
        "             self.steps_after_given_square += 1\n",
        "      \n",
        "      \n",
        "      if(self.task == \"count_all_objects\"):\n",
        "            #print(\"self.IsTouch: \", self.IsTouch)        \n",
        "            if(self.IsTouch==True and Action_inv[self.action]>self.n_motor_actions and Action_inv[self.action]<17):\n",
        "                self.counted_square_list.append(self.touched_square)\n",
        "                self.counted_word_list.append(self.action)\n",
        "                #print(\"counted word list updated\")\n",
        "        \n",
        "            counted_every_square_exactly_once = True\n",
        "            for i in range(len(self.squares)):\n",
        "                if(self.counted_square_list.count(i+1) !=1  ):\n",
        "                    counted_every_square_exactly_once = False\n",
        "                    \n",
        "            ## Check for one-to-one correspondence\n",
        "            all_squares_touched_exactly_once = True\n",
        "            for square in self.squares:\n",
        "                if(square.touched_count != 1):\n",
        "                    all_squares_touched_exactly_once = False\n",
        "            if(all_squares_touched_exactly_once):\n",
        "              self.one_to_one_correspondence = True\n",
        "            \n",
        "            if(counted_every_square_exactly_once == True and self.counted_none_object==False):\n",
        "              self.one_to_one_correspondence = True\n",
        "            \n",
        "            right_count_sequence = False\n",
        "            if(self.counted_word_list==self.aimed_count_list):\n",
        "                right_count_sequence = True\n",
        "                self.right_number_order = True\n",
        "              \n",
        "            if(counted_every_square_exactly_once and right_count_sequence):\n",
        "              self.ended = True\n",
        "    \n",
        "      if(self.task == \"touch_all_objects\"):\n",
        "            all_squares_touched_exactly_once = True\n",
        "            for square in self.squares:\n",
        "                if(square.touched_count != 1):\n",
        "                    all_squares_touched_exactly_once = False\n",
        "            if(all_squares_touched_exactly_once and self.counted_none_object==False):\n",
        "              self.one_to_one_correspondence = True\n",
        "            if(all_squares_touched_exactly_once):\n",
        "              self.ended = True\n",
        "              \n",
        "      if(self.task == \"move_all_squares_from_source_to_target\"):\n",
        "            all_squares_in_target = True\n",
        "            for square in self.squares:\n",
        "                if(square.pos.y < int(self.img_size*0.75)):\n",
        "                    all_squares_in_target = False\n",
        "            if(all_squares_in_target):\n",
        "              self.ended = True      \n",
        "\n",
        "      if(self.task==\"count_all_events_1\" or self.task==\"count_all_events_2\"):\n",
        "          if(self.one_step_after_event == True):\n",
        "               if(self.count_action==False):\n",
        "                  self.missed_count = True\n",
        "          if(self.count_action==True):\n",
        "            if(self.one_step_after_event == False):\n",
        "               self.counted_none_object = True\n",
        "            \n",
        "            if(self.missed_count == False and self.counted_none_object == False):\n",
        "               self.one_to_one_correspondence = True\n",
        "            else:\n",
        "               self.one_to_one_correspondence = False\n",
        "              \n",
        "                    \n",
        "            if(Action_inv[self.action]>self.n_motor_actions and Action_inv[self.action]<17):\n",
        "                if(self.one_step_after_event == True):\n",
        "                    self.counted_word_list.append(self.action)\n",
        "                    \n",
        "            right_count_sequence = False\n",
        "            if(self.counted_word_list==self.aimed_count_list):\n",
        "                right_count_sequence = True\n",
        "                self.right_number_order = True\n",
        "              \n",
        "            if(right_count_sequence):\n",
        "              self.ended = True        \n",
        "              \n",
        "      if(self.task == \"recite_n\" or self.task == \"recite_n_inverse\"):\n",
        "                    \n",
        "            if(Action_inv[self.action]>self.n_motor_actions and Action_inv[self.action]<17):\n",
        "                if(self.last_action_is_count == True):\n",
        "                    self.counted_word_list.append(self.action)\n",
        "                else:\n",
        "                    self.last_action_is_count = False\n",
        "                    \n",
        "            right_count_sequence = False\n",
        "            if(self.counted_word_list==self.aimed_count_list):\n",
        "                right_count_sequence = True\n",
        "                self.right_number_order = True\n",
        "              \n",
        "            if(right_count_sequence and self.action==\"stop\"):\n",
        "              self.ended = True  \n",
        "              \n",
        "      if(self.task == \"do_nothing\"):\n",
        "        if(self.action != \"stop\"):\n",
        "           self.did_nothing = False\n",
        "        if(self.time>self.n_squares-2 and self.did_nothing):\n",
        "           self.ended = True\n",
        "      \n",
        "      if(self.IsTripleAction == False):\n",
        "          if(self.save_epoch):\n",
        "              \n",
        "              img, action = envImageAndActionToPytorchFormat(self)\n",
        "              object_features = get_object_features(self)\n",
        "              dual_relations = get_dual_relations_from_features(object_features).float()\n",
        "              self.relations = dual_relations\n",
        "              action_string = self.readable_actionstring()\n",
        "              curr_exp = {'img': img, 'action': action, 'rel': dual_relations, 'dem_img': self.observationImg, 'action_string': action_string}\n",
        "              self.epoch.append(curr_exp)\n",
        "              \n",
        "          self.visObs = self.constructObs()\n",
        "          \n",
        "      \n",
        "        #Turn this on if you want to save the last frame in save_epoch as well for demonstration or anything\n",
        "      if(self.IsTripleAction == False):\n",
        "         if(self.save_epoch and self.ended):\n",
        "             img, action = envImageAndActionToPytorchFormat(self)\n",
        "             object_features = get_object_features(self)\n",
        "             dual_relations = get_dual_relations_from_features(object_features).float()\n",
        "             self.relations = dual_relations\n",
        "             action_string = self.readable_actionstring()\n",
        "             curr_exp = {'img': img, 'action': action, 'rel': dual_relations, 'dem_img': self.observationImg, 'action_string': action_string}\n",
        "             self.epoch.append(curr_exp)\n",
        "              \n",
        "      if(self.IsTripleAction == False):\n",
        "        self.time += 1\n",
        "        if(self.print_sub_tasks_after_steps == True):\n",
        "          print(\"One-to-one correspondence: \", self.one_to_one_correspondence)\n",
        "          print(\"Right number sequence: \", self.right_number_order)\n",
        "      else:\n",
        "        if(self.second_action == True):\n",
        "          self.time += 1\n",
        "          if(self.print_sub_tasks_after_steps == True):\n",
        "            print(\"One-to-one correspondence: \", self.one_to_one_correspondence)\n",
        "            print(\"Right number sequence: \", self.right_number_order)\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "Action = {\n",
        "    7: \"stop\",\n",
        "    8: \"1\",\n",
        "    9: \"2\",\n",
        "    10: \"3\",\n",
        "    11: \"4\",\n",
        "    12: \"5\",\n",
        "    13: \"6\",\n",
        "    14: \"7\",\n",
        "    15: \"8\",\n",
        "    16: \"9\"\n",
        "}        \n",
        "\n",
        "Action_inv = {\n",
        "    \"stop\": 7,\n",
        "    \"1\": 8,\n",
        "    \"2\": 9,\n",
        "    \"3\": 10,\n",
        "    \"4\": 11,\n",
        "    \"5\": 12,\n",
        "    \"6\": 13,\n",
        "    \"7\": 14,\n",
        "    \"8\": 15,\n",
        "    \"9\": 16\n",
        "}  \n",
        "\n",
        "readable_task = {\n",
        "    \"touch_all_objects\": \"Touch all objects\",\n",
        "    \"count_all_objects\": \"Count all objects\",\n",
        "    \"count_all_events\": \"Count all events\",\n",
        "    \"count_all_events_1\": \"Count all events 1\",\n",
        "    \"count_all_events_2\": \"Count all events 2\",\n",
        "    \"give_n\": \"Give N\",\n",
        "    \"recite_n\": \"Recite N\",   \n",
        "    \"do_nothing\": \"Do nothing\",\n",
        "    \"recite_n_inverse\": \"Recite N inverse\"\n",
        "}\n",
        "\n",
        "\n",
        "def create_pointer(width, height, pick=False):\n",
        "  #width += 1\n",
        "  #height += 1\n",
        "    \n",
        "  data = np.zeros((width,height), dtype=np.uint8)\n",
        "  data_mask = np.zeros((width,height), dtype=np.uint8)\n",
        "  \n",
        "  for i in range(width):\n",
        "    for j in range(height):\n",
        "      h = width - i -1\n",
        "      w = width - j -1\n",
        "      \n",
        "      strips = h\n",
        "      if(pick):\n",
        "        strips = w\n",
        "      \n",
        "      if(abs(j)<= width/2.0 ):\n",
        "        if(h <= j or h == j or h == j+2):\n",
        "          data_mask[i,j] = 255\n",
        "        if(h <= j and strips%2==0 or h == j+2  ):\n",
        "          data[i,j] = 255\n",
        "      else: \n",
        "        if(h <= w or h==w or h==w+2):\n",
        "          data_mask[i,j] = 255\n",
        "        if(h <= w and strips%2==0 or h==w+2):\n",
        "          data[i,j] = 255\n",
        "  return data, data_mask\n",
        "\n",
        "##########################################\n",
        "### CREATE ACTION-DISPLAY\n",
        "#########################################\n",
        "\n",
        "\n",
        "def create_count_window(img_size, n=0):\n",
        "\n",
        "  data = np.zeros((img_size,img_size), dtype=np.uint8)\n",
        "  data_mask = np.zeros((img_size,img_size), dtype=np.uint8)\n",
        "  line_width = int(img_size/10)+1\n",
        "  if(n==1):\n",
        "    draw_1(data, img_size, line_width)\n",
        "  if(n==2):\n",
        "    draw_2(data, img_size, line_width)\n",
        "  if(n==3):\n",
        "    draw_3(data, img_size, line_width)\n",
        "  if(n==4):\n",
        "    draw_4(data, img_size, line_width)\n",
        "  if(n==5):\n",
        "    draw_5(data, img_size, line_width)\n",
        "  if(n==6):\n",
        "    draw_6(data, img_size, line_width)\n",
        "  if(n==7):\n",
        "    draw_7(data, img_size, line_width)\n",
        "  if(n==8):\n",
        "    draw_8(data, img_size, line_width)\n",
        "  if(n==9):\n",
        "    draw_9(data, img_size, line_width)\n",
        "  if(n==10):\n",
        "    draw_P(data, img_size, line_width)  \n",
        "  if(n==11):\n",
        "    draw_U(data, img_size, line_width)  \n",
        "  if(n==12):\n",
        "    draw_T(data, img_size, line_width) \n",
        "  if(n==13):\n",
        "    draw_E(data, img_size, line_width) \n",
        "  return data\n",
        "  \n",
        "  \n",
        "  \n",
        "def draw_line(img, img_size, x_start, x_end, y_start, y_end):  \n",
        "  for i in range(img_size):\n",
        "      for j in range(img_size):          \n",
        "          if( (x_start<= i <=x_end) and (y_start<= j <=y_end)   ):\n",
        "              img[j,i] = 255\n",
        "              \n",
        "            \n",
        "\n",
        "\n",
        "def draw_line_1(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(img_size/4), int(3*img_size/4)+int(line_width), 0, line_width)\n",
        "    \n",
        "def draw_line_2(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(img_size/4), int(3*img_size/4), int(img_size/2)-int(line_width/2), int(img_size/2) + int(line_width/2))\n",
        "    \n",
        "def draw_line_3(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(img_size/4), int(3*img_size/4) + line_width, int(img_size)-line_width, int(img_size))\n",
        "    \n",
        "def draw_line_4(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(img_size/4), int(img_size/4)+line_width, 0, int(img_size/2))\n",
        "    \n",
        "def draw_line_5(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(img_size/4), int(img_size/4)+line_width, int(img_size/2), int(img_size))    \n",
        "\n",
        "def draw_line_6(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(3*img_size/4), int(3*img_size/4)+line_width, 0, int(img_size/2 + line_width/2))    \n",
        "    \n",
        "def draw_line_7(img, img_size, line_width):\n",
        "    draw_line(img, img_size, int(3*img_size/4), int(3*img_size/4)+line_width, int(img_size/2)-int(line_width/2), int(img_size))  \n",
        "\n",
        "\n",
        "# Draw \"T\" for \"Terminate\"    \n",
        "def draw_line_8(img, img_size, line_width):\n",
        "    draw_line(img, img_size, img_size/8, int(3*img_size/4)+int(line_width), 0, line_width) \n",
        "def draw_line_9(img, img_size, line_width):\n",
        "    draw_line(img, img_size, img_size/2-line_width, img_size/2+line_width, 0, img_size) \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "def draw_1(img, img_size, line_width):    \n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)\n",
        "\n",
        "    \n",
        "    \n",
        "def draw_2(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)  \n",
        "\n",
        "def draw_3(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width) \n",
        "    \n",
        "def draw_4(img, img_size, line_width):    \n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)     \n",
        "\n",
        "def draw_5(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)     \n",
        "\n",
        "def draw_6(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)     \n",
        "\n",
        "def draw_7(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)     \n",
        "    \n",
        "    \n",
        "def draw_8(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width) \n",
        "    \n",
        "\n",
        "def draw_9(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width)    \n",
        "\n",
        "def draw_P(img, img_size, line_width):    \n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "     \n",
        "def draw_U(img, img_size, line_width):    \n",
        "    #draw_line_1(img, img_size, line_width)\n",
        "    #draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    draw_line_6(img, img_size, line_width)\n",
        "    draw_line_7(img, img_size, line_width) \n",
        " \n",
        "\n",
        "def draw_T(img, img_size, line_width):    \n",
        "    draw_line_8(img, img_size, line_width)\n",
        "    draw_line_9(img, img_size, line_width)\n",
        "    \n",
        "def draw_E(img, img_size, line_width):    # End\n",
        "    draw_line_1(img, img_size, line_width)\n",
        "    draw_line_2(img, img_size, line_width)\n",
        "    draw_line_3(img, img_size, line_width)\n",
        "    draw_line_4(img, img_size, line_width)\n",
        "    draw_line_5(img, img_size, line_width)\n",
        "    #draw_line_6(img, img_size, line_width)\n",
        "    #draw_line_7(img, img_size, line_width) \n",
        "    \n",
        "    \n",
        "#count_window = create_count_window(50, n=13)    \n",
        "#img = Image.fromarray(count_window).resize( (400,400))   \n",
        "#display(img)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Count-Environment....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iog-Qmpie27p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def demonstrate_model(env, model, PATH=None, display_=False):\n",
        "  \n",
        "      #print(\"in demonstrate..\")   \n",
        "      model.training = False\n",
        "      state_network = None\n",
        "\n",
        "      env.rand_n_squares = False\n",
        "      env.save_epoch = True\n",
        "      \n",
        "      env.reset()\n",
        "      if(display_):\n",
        "        display(env.observationImg.convert('RGB'), display_id = \"game\")\n",
        "        update_display(env.observationImg.convert('RGB'), display_id = \"game\")\n",
        "\n",
        "      delay_time = 0.20\n",
        "\n",
        "      image_list = []\n",
        "      cell_list = []\n",
        "      hidden_list = []\n",
        "\n",
        "      env.reset()\n",
        "      max_t = env.max_time\n",
        "      t=0\n",
        "      state_network = None\n",
        "      n=0\n",
        "      task_vector_size = 5\n",
        "\n",
        "      state_network_vis = None\n",
        "      state_network_lang = None\n",
        "      input_lang = torch.zeros( (1, env.n_words+1) ).view(1, env.n_words+1)\n",
        "      task_vector = torch.zeros(task_vector_size)\n",
        "      task_vector[env.task_n] = 1\n",
        "\n",
        "      task_vector = create_task_vector(env)\n",
        "      task_vector = task_vector.reshape(1, env.task_vector_length)\n",
        "      \n",
        "      a_is = []\n",
        "\n",
        "      while(t<max_t and env.ended == False):\n",
        "          '''\n",
        "          t += 1\n",
        "\n",
        "          image, action = envImageAndActionToPytorchFormat(env)\n",
        "          #stacked_img_coord = add_coordinate_layers(image, env.img_size, env.task_n)\n",
        "          state_network, Q_values = model.forward(image, state_network)\n",
        "          a = np.argmax(Q_values.detach().numpy()).item()\n",
        "          print(a)\n",
        "          env.update(a)\n",
        "          '''\n",
        "\n",
        "          ################NEW PART END      \n",
        "\n",
        "          #if(n==0):\n",
        "          #    env.display = \"Game\"\n",
        "          t += 1\n",
        "\n",
        "          image, action = envImageAndActionToPytorchFormat(env)\n",
        "          #stacked_img_coord = add_task_layer(image, env.img_size, env.task_n)\n",
        "          #stacked_img_coord = add_task_layer(image, env.img_size, env)\n",
        "          stacked_img_coord = image\n",
        "\n",
        "          #state_network, Q_values = model.forward(stacked_img_coord, state_network)\n",
        "          state_network_vis, output_action, state_network_lang, output_lang = model(stacked_img_coord,state_network_vis, input_lang, state_network_lang, task_vector)\n",
        "          #print(\"###########################\")\n",
        "          #print(\"whole action: \", torch.cat((output_action, output_lang),1))\n",
        "          #print(\"output_lang.detach().numpy(): \", output_lang.detach().numpy() )\n",
        "          #print(\"output_action.detach().numpy(): \", output_action.detach().numpy() )\n",
        "          #print(\"output_lang.detach().numpy()[0][:-1]: \", output_lang.detach().numpy()[0][:-1] )\n",
        "          #print(\"output_lang[0][-1].detach().numpy(): \", output_lang[0][-1].detach().numpy())\n",
        "\n",
        "\n",
        "          Q_values = torch.cat((output_action, output_lang),1)\n",
        "          #print(Q_values[0].tolist())\n",
        "\n",
        "          a = int(np.argmax(output_action.detach().numpy()[0][:-1]).item() )\n",
        "          Is_a = bool( round( output_action[0][-1].detach().numpy().item() ) )\n",
        "\n",
        "          #print(output_lang.detach().numpy()[0][-1])\n",
        "          c = bool( round( output_lang[0][-1].detach().numpy().item() ) )\n",
        "\n",
        "\n",
        "          word = int(np.argmax(output_lang.detach().numpy()[0][:-1]).item() )\n",
        "\n",
        "          triple_action_arr = np.concatenate((output_action.detach().numpy(),output_lang.detach().numpy()), axis=None)\n",
        "          #print(np.around(triple_action_arr,decimals=2))\n",
        "          #print(\"Motor-Action:\" , np.around(output_action.detach().numpy(),decimals=2))\n",
        "          #print(\"Verbal-Action:\" , np.around(output_lang.detach().numpy(),decimals=2))\n",
        "\n",
        "          \n",
        "          #if(c):\n",
        "          #    print(word+1)\n",
        "          #    print(state_network_lang)\n",
        "\n",
        "          #print(\"word: \", word)\n",
        "          #print(\"a: \", Action[a]  )\n",
        "          #print(\"word: \", word)\n",
        "          #print(\"Action[word]: \", Action[word])\n",
        "          #print(\"c: \", c)\n",
        "          #print(\"int(a): \", int(a))\n",
        "          env.triple_update(int(a), Is_a, int(word+env.n_motor_actions),c )\n",
        "\n",
        "\n",
        "          #print(\"c: \", c)\n",
        "          #c = True\n",
        "          input_lang = torch.zeros( env.n_words+1 ) #.view(1, env.n_words+1)\n",
        "          #if(c==True):\n",
        "          #  input_lang[word-4] = 1\n",
        "          #  input_lang[env.n_words] = 1\n",
        "\n",
        "          #print(\"input_lang: \", input_lang)\n",
        "          #input_lang = input_lang.view(1, env.n_words+1)\n",
        "          input_lang = copy(output_lang)\n",
        "          \n",
        "          \n",
        "          \n",
        "          ##### get variability:\n",
        "          action_length = output_action.detach().numpy()[0][:-1].size\n",
        "          verbal_length = output_lang.detach().numpy()[0][:-1].size\n",
        "          n_actions = action_length + verbal_length\n",
        "          #print(\"n_actions:\", n_actions)\n",
        "          \n",
        "          if(Is_a):\n",
        "          \ta_is.append(a)\n",
        "          if(c):\n",
        "            a_is.append(word)\n",
        "\n",
        "\n",
        "          ################NEW PART END      \n",
        "\n",
        "\n",
        "          if(display_):\n",
        "            \n",
        "            img_input = env.observationImg.convert('RGB')\n",
        "            img_memory = Image.fromarray(state_network_vis[0][0][0].detach().numpy()*255).resize( (400,400)).convert('RGB')\n",
        "            \n",
        "            imgs = get_concat_h(img_input, img_memory)\n",
        "            \n",
        "            update_display(imgs, display_id = \"game\")\n",
        "            #update_display(img_memory, display_id = \"cell\")\n",
        "            time.sleep(delay_time*2)\n",
        "\n",
        "          image_list.append(env.observationImg.convert('RGB'))\n",
        "          #hidden_list.append(Image.fromarray(state_network[0][0][0].detach().numpy()*255).resize( (400,400)).convert('RGB'))\n",
        "          #cell_list.append(Image.fromarray(state_network[1][0][0].detach().numpy()*255).resize( (400,400)).convert('RGB'))\n",
        "\n",
        "\n",
        "          if(env.ended and display_==True):\n",
        "              print(\"                               \")\n",
        "              print(\"\\\\------------------------------/\")\n",
        "              print(\" \\\\----------------------------/\")\n",
        "              print(\"  Congrats - successful trial!\")   \n",
        "              print(\" /----------------------------\\\\\")\n",
        "              print(\"/------------------------------\\\\\")\n",
        "      \n",
        "      \n",
        "      ### get variability\n",
        "      f_is = []\n",
        "      action_sequence_length = len(a_is)\n",
        "      \n",
        "      for i in range(n_actions):\n",
        "        f_is.append(a_is.count(i)/action_sequence_length)\n",
        "      \n",
        "      sum_of_squared_f_is = 0\n",
        "      for i in range(len(f_is)):\n",
        "        sum_of_squared_f_is += f_is[i]*f_is[i]\n",
        "      \n",
        "      variability = 1-np.sqrt(sum_of_squared_f_is)\n",
        "      #print(\"Variability: \", variability)\n",
        "      \n",
        "      if(PATH is not None):\n",
        "\n",
        "        text_path = PATH + \".txt\"\n",
        "        gif_path = PATH + \".gif\"\n",
        "        all_text_path = model.model_path + \"actions.txt\"\n",
        "        all_text_path_html = model.model_path + \"actions.html\"\n",
        "        \n",
        "        #print(\"saving gifs and action sequence...\")\n",
        "        #print(text_path)\n",
        "        #print(gif_path)\n",
        "        \n",
        "        #save_gif(env, gif_path)\n",
        "        #save_action_sequence(env, text_path, model.episode)\n",
        "        save_action_sequence(env, all_text_path, model.episode)\n",
        "        save_action_sequence_to_html(env, all_text_path_html, model.episode)\n",
        "              \n",
        "def save_gif(env, PATH, display = False):\n",
        "    images = []\n",
        "    new_size = 840\n",
        "    background = Image.new(\"RGB\", (new_size,new_size))\n",
        "    #display(new_im, display_id = \"game\")\n",
        "    white = (255,255,255)\n",
        "\n",
        "    for t in range(0, len(env.epoch) ):\n",
        "\n",
        "            old_size = 800\n",
        "            img = env.epoch[t]['dem_img'].resize( (old_size,old_size) ).convert('RGB')\n",
        "\n",
        "            old_im = img\n",
        "            new_im = background\n",
        "            new_im.paste(old_im, ( int( (new_size-old_size)/2) ,\n",
        "                          int( (new_size-old_size)/2) ))\n",
        "            \n",
        "            #images.append( new_im.resize( (400,400) ) )\n",
        "            images.append( img )\n",
        "            if(display):\n",
        "                update_display(new_im, display_id = \"game\")\n",
        "                time.sleep(0.3)\n",
        "    images.append(Image.new(\"RGB\", (new_size,new_size),white))\n",
        "    images[0].save(PATH, format='GIF', append_images=images[1:], save_all=True, duration=500, loop=0)              \n",
        "\n",
        "    \n",
        "    \n",
        "def save_action_sequence(env, PATH, episode):\n",
        "    whole_text = \"\"\n",
        "    if(env.n_squares==1):\n",
        "      whole_text += \"\\n Episode: \" + str(episode)\n",
        "      whole_text += \"\\n   Task: \" + str(readable_task[env.task]) + \"\\n\"\n",
        "    whole_text += \"     n= \" + str(env.n_squares) + \": \"\n",
        "    for a in range(len(env.epoch)-1):\n",
        "        #print( [a_strings[i] for i in range(len(a_strings)) if env.epoch[a]['action'][0].tolist()[i] and i!=env.n_actions-1  and i!=env.n_motor_actions] )\n",
        "        whole_text += \"   \" + str([env.a_strings[0][i] for i in range(len(env.a_strings[0])) if env.epoch[a]['action'][0].tolist()[i] and i!=env.n_actions-1  and i!=env.n_motor_actions]) + \",\"\n",
        "    whole_text += \"\\n\"\n",
        "    \n",
        "    fily = open(PATH,\"a+\")\n",
        "    fily.write(whole_text)\n",
        "    fily.close()\n",
        "\n",
        "def save_action_sequence_to_html(env, PATH, episode):\n",
        "    whole_text = \"\"\n",
        "    if(env.n_squares==1):\n",
        "      whole_text += \"<br> Episode: \" + str(episode)\n",
        "      whole_text += \"<br>   Task: \" + str(readable_task[env.task]) + \"<br>\"\n",
        "    whole_text += \"     n= \" + str(env.n_squares) + \": \"\n",
        "    for a in range(len(env.epoch)-1):\n",
        "        #print( [a_strings[i] for i in range(len(a_strings)) if env.epoch[a]['action'][0].tolist()[i] and i!=env.n_actions-1  and i!=env.n_motor_actions] )\n",
        "        text = \"   \" + str([env.a_strings[0][i] for i in range(len(env.a_strings[0])) if env.epoch[a]['action'][0].tolist()[i] and i!=env.n_actions-1  and i!=env.n_motor_actions]) + \",\"\n",
        "        back_ground_color, text_color = color_of_string(text)\n",
        "        whole_text += \"<span style=\\\"background-color: \" + back_ground_color + \";color: \" + text_color + \" \\\"> \" + text + \"</span>\"\n",
        "    whole_text += \"<br>\"\n",
        "    \n",
        "    fily = open(PATH,\"a+\")\n",
        "    fily.write(whole_text)\n",
        "    fily.close()\n",
        "def color_of_string(action_string):\n",
        "  number_strings = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
        "  back_ground_colory = \"#FFFFFF\"\n",
        "  colory = \"black\"\n",
        "\n",
        "  if(\"Dr\" in action_string):\n",
        "    colory = \"blue\"\n",
        "\n",
        "  if(\"P\" in action_string):\n",
        "    colory = \"blue\"\n",
        "\n",
        "  if(\"E\" in action_string):\n",
        "    back_ground_colory = \"orange\"\n",
        "\n",
        "  if any(ext in number_strings for ext in action_string):\n",
        "     back_ground_colory = \"yellow\"\n",
        "\n",
        "  return back_ground_colory, colory\n",
        "\n",
        "\n",
        "def get_concat_h(im1, im2, distance = 50):\n",
        "    dst = Image.new('RGB', (im1.width + im2.width + distance, im1.height), color='white')\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (im1.width + distance, 0))\n",
        "    return dst\n",
        "\n",
        "def get_concat_v(im1, im2, distance=50):\n",
        "    dst = Image.new('RGB', (im1.width, im1.height + im2.height + distance), color='white')\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (0, im1.height + distance))\n",
        "    return dst    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzwicRwyfIyk",
        "colab_type": "code",
        "outputId": "392fe143-4254-42eb-b463-aa94984eb637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "########################\n",
        "## LOAD MODEL and Demonstrate\n",
        "########################\n",
        "\n",
        "c = 2           # Input size\n",
        "d = 1           # Hidden size\n",
        "lr_dummy = 0.25\n",
        "env = CountEnv(mode=\"pick_square\", max_dist = 10, n_squares = 2, display = \"game\", save_epoch = True )\n",
        "env.task=\"touch_all_objects\"\n",
        "env.rand_n_squares = False\n",
        "env.print_action_onehot_aftersteps = False\n",
        "env.reset()\n",
        "\n",
        "model = LangConvLSTMCell(c,d,env,lr_dummy)\n",
        "\n",
        "PATH = \"/content/drive/My Drive/Embodied_counting/Results/touch_all_objects___from_pretrained_1_TIMES__4135/touch_all_objects_1_to_5_20-01-23-15-00model-6131_/touch_all_objects_1_to_5_20-01-23-15-00model-6131_\"\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#train_model(task_list=[\"give_n\"], n_squares_=2, num_epochs=200, model=model)\n",
        "#test_model(env,model,n_test_runs=20)\n",
        "\n",
        "\n",
        "demonstrate_model(env, model, display_=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAGQCAIAAAAr+8bGAAAHvUlEQVR4nO3dQWrDQBBFwXTwvYVO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\nAECC7AMASJB9AAAJsg8AIEH2AQAk/AA0/BssV/7OfQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=850x400 at 0x7F658A8183C8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               \n",
            "\\------------------------------/\n",
            " \\----------------------------/\n",
            "  Congrats - successful trial!\n",
            " /----------------------------\\\n",
            "/------------------------------\\\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AotEvpdMfI1X",
        "colab_type": "code",
        "outputId": "5777df48-8c4a-48f5-9d1a-adf0d101533f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from PIL import ImageDraw \n",
        "from PIL import ImageFont\n",
        "from PIL import Image, ImageOps\n",
        "#font = ImageFont.truetype(\"arial.ttf\", 16)\n",
        "\n",
        "draw = ImageDraw.Draw(img)\n",
        "draw.text((0, 0),\"Sample Text\",(255,255,255)) #,font=font\n",
        "\n",
        "\n",
        "\n",
        "task_vector = create_task_vector(env)\n",
        "task_vector = task_vector.reshape(1, env.task_vector_length)\n",
        "task_vector = task_vector.detach().numpy().reshape(env.task_vector_length)\n",
        "\n",
        "\n",
        "for i in range(task_vector.size):\n",
        "  if(i%2==0):\n",
        "    task_vector[i] = 0.5\n",
        "\n",
        "\n",
        "double_task_vector = np.stack( (task_vector,task_vector))\n",
        "print(double_task_vector.shape)\n",
        "print(type(task_vector))\n",
        "print(task_vector[:].shape)\n",
        "print(env.task_vector_length)\n",
        "img_width = env.task_vector_length*45\n",
        "img_height = img_width//20\n",
        "img = Image.fromarray(double_task_vector*255).resize( (img_width,img_height)).convert('RGB') #.resize( (img_width,img_hight)).convert('RGB')\n",
        "\n",
        "\n",
        "boundary_color = (0,0,255)\n",
        "boundary_width = 4\n",
        "\n",
        "drawy = ImageDraw.Draw(img)\n",
        "for i in range(env.task_vector_length):\n",
        "   drawy.line((i*img_height - boundary_width//2 ,0, i*img_height- boundary_width//2,img_height), fill=boundary_color, width = boundary_width )\n",
        "\n",
        "border_width = 5\n",
        "img = ImageOps.expand(img, border=border_width, fill = boundary_color)\n",
        "\n",
        "text_img = Image.new('RGB', (img.width, img.height), color='white')\n",
        "draw = ImageDraw.Draw(text_img)\n",
        "node_names_list = [\"Touch\", \"Recite\", \"Count\", \"Give\",\"Nothing\",\"1\", \"2\",\"3\", \"4\",\"5\", \"6\",\"7\", \"8\",\"9\", \"ALL\",\"Objects\", \"Events\",\"-\", \"-\", \"-\"]\n",
        "\n",
        "\n",
        "\n",
        "for w_i in range(len(node_names_list)):\n",
        "  wordy = node_names_list[w_i]\n",
        "  draw.text((border_width + w_i*img_height + img_height//2 - 3*len(wordy), 40),wordy,(0,0,0))\n",
        "\n",
        "task_img = get_concat_v(text_img, img, distance=0)\n",
        "\n",
        "\n",
        "\n",
        "display(task_img)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 20)\n",
            "<class 'numpy.ndarray'>\n",
            "(20,)\n",
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAABuCAIAAADnOdrcAAAFW0lEQVR4nO3d0ZbbJhQFUKmr/53m\ny9UHd6mMQDKyZXFa7/0048zANcJwRJx4XpZlAgCAPH+MLgAAANpEVQAAQomqAACEElUBAAglqgIA\nEEpUBQAglKgKAEAoURUAgFCiKgAAoURVAABCiaoAAIQSVQEACCWqAgAQSlQFACCUqAoAQChRFQCA\nUKIqAAChRFUAAEKJqgAAhBJVAQAIJaoCABBKVAUAIJSoCgBAKFEVAIBQoioAAKFEVQAAQomqAACE\nElUBAAglqgIAEEpUBQAglKgKAEAoURUAgFCiKgAAoURVAABCiaoAAIQSVQEACCWqAgAQSlQFACCU\nqAoAQChRFQCAUKIqAACh/rytp3meH18sy3Jzp2uPm2+H+2g9A59s2fXBdR9SYcIcGPJaiC3jYex1\nWYfiYeCAJFwUo5FZxkddu1AnvJz/xxfrC3VF1UtWrmVZNu10Kn/rbNcfTYEf7eKU5irzicLWJaB/\n7T647kNC6nDlGM7zPHw1H1tGWcxww1/LURfl5RX7KiGjMaSMzRZT7ziX7EHlMj58oc65QSJQV1Rd\nJ3E5m8tZXn99cKL22h3PZqWoW948cvDa7jzz21MPxfRsNDbfHtTzgnol3Vvmeq5OZ4+Ppprt7D2v\nZtdTa3bVv3LJXXLd9RAhS3BIGVMxnUYXEnQYMzykDuyd6dne0XzkrL0IfrBQlz9w8MjxVntcc7PN\nvW2ruUG80zuxTr9Xtbzw69fNa388Ud7ZmeqW60cet4l15eUf7VXYaa+dejQ2f1QvOpe8eNZ2Ng2e\nujpnNUd+U09ZRvPqNMfn2pyaJuFJPbaosWUkJNRVyM3Mel2GlzENnRvNVWVsGUO6HtLp3jbaufmu\nTdX58vhJHS9Kza326cba3/tZ808XtqyMjTveq3rJ5Kinb3MsXugrYVd4X32nW1pvnaeOMXwq5Azs\nv2v47vuwruN7d5u3KQ9CBm7PIeqDru9U3qyOHY3702qZAgNnwtnNd90yni59myOMS7at/t7PCrku\n31DGHVH1kvlRL1hP77qelnTQTo8L5/37Tb0WHz89xQMX2eFCTouj4vI0uh4TdSNkeiQYOBTNVX0v\nut1ZYf/muzmd7Qnfp+LssRd6J1PXNWsGu/oYb/OiWn6+S3J6dZMuG9m0UDdef9v/Y2dfAFP3aNSV\nH/ziC5p9lY+sP7Z3b3rqWjT/2mVqrZ7TznPfmyrLzruO+it8Wvym3zfbfL+MgYvmJXPvKsOj6vp1\nyAFzQhnDJ0bUaNxZxt5SeeCdv1E82DWmajI83XxPNV7//OZnjretno01Z8nlZW4vSBeyawJ8ISsw\nw933/6rCKTkHXQBfKORUG5yqAgAQygerAgAQSlQFACCUqAoAQKh5mrxXFQCARE5VAQAIJaoCABBK\nVAUAIJSoCgBAqManVf369dftZfzj9++y697PPv6Af/+pmdEIHI2BH1tRfpp0yGiYG0ajZDRKRqNk\nNEpGoxQzGqsf27xTVQAAQomqAACEElUBAAglqgIAEEpUBQAglKgKAEAoURUAgFCiKgAAoURVAABC\niaoAAIQSVQEACCWqAgAQSlQFACCUqAoAQChRFQCAUKIqAAChRFUAAEKJqgAAhBJVAQAIJaoCABBK\nVAUAIJSoCgBAKFEVAIBQoioAAKFEVQAAQomqAACEElUBAAglqgIAEEpUBQAglKgKAEAoURUAgFCi\nKgAAoURVAABCiaoAAIQSVQEACCWqAgAQSlQFACCUqAoAQChRFQCAUKIqAAChRFUAAEKJqgAAhBJV\nAQAIJaoCABBqnqZldA0AANDgVBUAgFCiKgAAoURVAABCiaoAAIT6Gxz5x/iT9K2kAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=910x110 at 0x7F658C9E4710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6LPKi8IOdFq",
        "colab_type": "code",
        "outputId": "30ce587d-6816-4e60-d86d-4195b8a40515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = \"wordy\"\n",
        "len(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJHgBDr5nV-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYfTFDLfpK4B",
        "colab_type": "code",
        "outputId": "7529b654-6a95-4c02-fc77-5b4b39bb34fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        }
      },
      "source": [
        "display(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAAZCAIAAABIGUs1AAABUUlEQVR4nO3bzXLCIBQGUGF8/0eG\nLrAMJT9TkdaWnLMiSNDJ4sv1ThJCCLdJcs6ztlqey/4WLjvXEd/9AwCY7z5ro5RSHU+sj46UuukX\nvgjgP7rfvuZyjIO1fIwx5/zUf9XtYmENMMW9JHvJ9JrydRBjbKP/aOZo9xrfR6kdQqg1eF3cndUe\ndvcD9TvArkcup5RSSm3E13GX3e1Md0votMm7W9F3odyu3I7bwzrTjgGoYlEOdqv4uu421LQZe6ig\nO6tN84HdAK4mtoFebGdeET69cta2Y1M92+gHuIJHkX4U8ee6Sr+N4Jxzba2c5O9Jn72eddSc2X4E\nQDHYs96t7lXQ3+dtmrdw2bmOkd7L9qEaAP6UkZeYZrXjAfghYhpgQcIdYEHCHWBBwh1gQcIdYEHC\nHWBBwh1gQcIdYEHCHWBBwh1gQcIdYEHCHWBBwh1gQR9QVMkYbaIEZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=500x25 at 0x7F658B04EC18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZS9Z_yPpguA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network_array_to_image(array_,node_names_list=None, layer_description=None, img_width=45):\n",
        "      \n",
        "      array_ = array_.detach().numpy()\n",
        "      array_size = array_.size\n",
        "\n",
        "      array_ = array_.reshape(array_size)\n",
        "\n",
        "      '''\n",
        "      for i in range(task_vector.size):\n",
        "        if(i%2==0):\n",
        "          task_vector[i] = 0.5\n",
        "      '''\n",
        "      double_array_ = np.stack( (array_,array_))\n",
        "\n",
        "      img_width = array_size*img_width\n",
        "      img_height = img_width//array_size\n",
        "      img = Image.fromarray(double_array_*255).resize( (img_width,img_height)).convert('RGB') \n",
        "\n",
        "      boundary_color = (0,0,255)\n",
        "      boundary_width = 4\n",
        "\n",
        "      drawy = ImageDraw.Draw(img)\n",
        "      for i in range(array_size):\n",
        "        drawy.line((i*img_height - boundary_width//2 ,0, i*img_height- boundary_width//2,img_height), fill=boundary_color, width = boundary_width )\n",
        "\n",
        "      border_width = 5\n",
        "      img = ImageOps.expand(img, border=border_width, fill = boundary_color)\n",
        "\n",
        "      text_img = Image.new('RGB', (img.width, img.height), color='white')\n",
        "      draw = ImageDraw.Draw(text_img)\n",
        "\n",
        "      task_font = ImageFont.truetype(\"/content/drive/My Drive/Embodied_counting/src/Arial.ttf\", 24)\n",
        "      node_font = ImageFont.truetype(\"/content/drive/My Drive/Embodied_counting/src/Arial.ttf\", 12)\n",
        "\n",
        "\n",
        "      #node_names_list = [\"Touch\", \"Recite\", \"Count\", \"Give\",\"Nothing\",\"1\", \"2\",\"3\", \"4\",\"5\", \"6\",\"7\", \"8\",\"9\", \"ALL\",\"Objects\", \"Events\",\"-\", \"-\", \"-\"]\n",
        "      if(node_names_list is not None):\n",
        "          for w_i in range(len(node_names_list)):\n",
        "            wordy = node_names_list[w_i]\n",
        "            draw.text((border_width + w_i*img_height + img_height//2 - 3*len(wordy), 40),wordy,(0,0,0), font=node_font)\n",
        "\n",
        "\n",
        "      description_img = Image.new('RGB', (img.width, img.height), color='white')\n",
        "      draw_description = ImageDraw.Draw(description_img)\n",
        "      if(layer_description is not None):\n",
        "          wordy = layer_description\n",
        "          draw_description.text((img_width//2 - 3*len(wordy), 0),wordy,(0,0,0),font=task_font)\n",
        "\n",
        "      array_img = get_concat_v(text_img, img, distance=0)\n",
        "      array_img = get_concat_v(array_img, description_img, distance=0)\n",
        "\n",
        "      return array_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T_lc_to4il1",
        "colab_type": "code",
        "outputId": "55a5dfae-b9b9-440c-fb98-f1495a69e658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "task_vector = create_task_vector(env)\n",
        "node_names_list = [\"Touch\", \"Recite\", \"Count\", \"Give\",\"Nothing\",\"Objects\", \"Events\",\"-\", \"-\", \"-\",\"1\", \"2\",\"3\", \"4\",\"5\", \"6\",\"7\", \"8\",\"9\", \"ALL\"]\n",
        "layer_description = \"TASK VECTOR\"\n",
        "\n",
        "img = network_array_to_image(array_=task_vector,node_names_list=node_names_list, layer_description=layer_description)\n",
        "display(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAClCAIAAACcFjSrAAAf0klEQVR4nO3deVxVdf7H8e9lFZCL\nGqAoiCgqiEtjuOVSimbiGprbuFBplo2pbZQ1ToummY/RxMQ0FLWRLNHUTMsFFwZxaRRNMw0FREFZ\nZJOde35/fH9z58a94AXMe6zX86/rud9zvp/zPXeYd9+zaRRFEQAAAID6WFm6AAAAAMA0oioAAABU\niqgKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgK\nAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAA\nlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKq\nAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAA\nQKWIqgAAAFApoioAAABUiqgKAAAAlSKqAgAAQKX+dFG1vLxcURRLV1EtlZdXBw/oHqmhbDXUAACA\nZZkVVZ988kmNkYyMjDr3eurUKT8/PzMb5+bmGvar1WqHDx+elZVVq+58fX2FEDqd7uGHHy4tLa1L\n0b+1bt26hx9+2NHR0cfH58MPP7wnkaI+5X3zzTe9e/d2dnZ2dnYeNGjQiRMnhMGO3ytZWVkajWbD\nhg36JatXrx41alR17fV7ZPKI17O8qKiozp07N2jQwNPTc86cOQUFBUKIhIQE445MLqxBbQ9EYWGh\n8f9ALl68aH6P9a8BfySvv/764sWLLVjAwoULvby8nJycgoKCkpKSLFXG6tWrvby8GjZs+Oyzz5aU\nlFiqDCk2NrZJkyYWLODll1/W/3kJDAy0VBlnz57t3r27g4NDYGDgmTNnLFLD8uXLq/y9TUtLs0gl\nhw4d6tChg1arHTduXH5+vkVqEEJs3769Xbt2Wq322WefLSoqum/96nQ6T0/PkSNH6pckJydrNJqK\nigrDZiYX1o5SGy1atIiNja3VKiadPHmyffv2Zja+ffu2ECIzM1P+Mzk5uU+fPjNmzKhDv+Xl5UKI\n4uLiOqxr6P3332/Xrt3hw4eLiopOnz4dEBAwb968em6zPuVFRka6ubl98cUXt27dSk9PX7p0qYuL\ny/Xr1+tfUhWZmZlCiC5duuTm5solERERI0eOrK69fo9qdcTNsXjx4pYtW+7cuTM/P//SpUujR48O\nDAwsKys7duxY/Tuq7YGQKTk9Pb2e/danBvwxFBcXz507VwixaNEiS9Wwd+/e9u3b//rrr4WFhXPn\nzn300UctUsapU6e8vLxOnz6dlZXVv3//BQsWWKQM6c6dO76+vi4uLhasISgo6IcffrBgAYqilJSU\neHt7r127Nj8/f9myZX/5y18sW4+iKDNnzpw2bZpFui4rK3Nzc4uOjr59+/aIESNee+01i5Rx+fJl\nR0fH7du35+bmTp48+X6Oxg8//PDII480atToxo0bcsnVq1fFf08J6plcWCv1iqo7duzw9/d3dnYe\nNmxYWlqaoihHjx4NCAiQ3x49erRLly7yc0xMTNu2bR0dHYcMGZKVlXXy5MnWrVvPnDmzUaNG7du3\nP3nyZA2dVomqiqKEh4f36tVLft63b1+nTp20Wu2YMWNycnKq665NmzaKovTo0UMG9PT0dJMrmiMn\nJ8fOzu7s2bP6JcePH588eXKtxuTkyZOBgYFjxoxxcXHp0qWL3JpheebXU1ZW1qRJk2+//dZw4bJl\nyxITE/U7HhISEh4eLr+KjIyU4bIOIyCj6oYNG15++WW5xDCqGu+7fo9MHnF9eSZHQ1GU9evXN2/e\nvEWLFosWLfL29taXkZWV5eDgkJiYqF9SXl7u7++/Zs2aY8eOtWnTZvr06Y0aNerfv39KSoqiKIb5\n1ZwfjOGBmDp1qlar9fHxWbhwYXXDUl1UNXPY7/pjMKcG/DFMmjTp6aefnjRpkgWjqqH09HRbW1ud\nTmfZMsLDw8eMGWPBAubMmfP8889bNqp6eHjc2/8eroPdu3cPHDjQsjUYOnr0qIeHR35+vkV6T0pK\ncnZ2lp+3bt3at29fi5SxcuXKUaNGyc+pqanOzs4VFRX3p+tJkybNmzfvqaeekueWld8tqtb9WtVf\nf/01NDR02bJlqampXl5eEydOrK7l1atXp0yZsnz58mvXrjVv3jwsLEwIceXKlVatWl2/fn3o0KHz\n5s0zs1NFUZKSktatWydPf9y4cSMkJOT9999PTU318PD429/+Vl13UlxcnBCiuLhYp9MZr2imI0eO\neHp6durUSb+ke/fuGzdurNWYCCFOnTr12GOPpaSk9O7dW46AvrxmzZqZX09CQoIQIjg42HDhnDlz\nOnfurP/n2LFjt23bJj/HxMSMHTvW5NCZafLkyYmJiefOnTNcaHLf9Xsk7nbEjUfj/Pnzc+bM2bJl\ny6lTp7799lvDxvIQGO6gjY3NuHHjvvvuOyFEUlJSmzZtkpOTH3744WeeecZwRTN/MPqyY2Nj09LS\nrl27tn///vDw8PPnz5s/SqI2w17Dj6GeNeDB8vHHH3/11VcuLi6WLuT/xcfHd+rUSaPRWLCG1NTU\nL774YvDgwZYqICEhIS4u7vXXX7dUAUKI3NzcrKysKVOmNGzYsF+/fr/88otFykhMTPTw8BgyZIij\no+Njjz0mI4gFhYWFzZ8/39nZ2SK9e3p6arXaLVu25OfnR0dHd+/e3SJlVFZWOjo6ys/W1tYFBQW1\nukKyzgoLC3fs2PHMM89MnTo1MjJS+V3vrKhVsDWcVV26dKl+KrGoqMjOzu769esmZxDDw8P1kV86\nefKku7u7/Hz8+PGaz9jKWVU9Z2fn0NBQeQJ65cqVw4cPl83u3Llja2tbWlpqsjs5e6c/qWpyRTMH\nYd26dT169DD5lfljcvLkySZNmsiF8fHx/v7+Sl3P+X711VcdOnSQn+X0nvTSSy/pd7ywsFCr1WZl\nZeXl5bm4uBQUFNRtBOSsqqIoZ86c6d+/v2Iwq2py3w0vADA+4oazqsaj8f7770+fPl0uPHDggOGs\n6urVq41PSsqFx44d8/T0lJNAd+7csba2zs3N1c+qmvmD0Ze9c+dODw+PiIgIOUlcHcNhl2R3Zg57\nzT8GM2vAH8lLL72khlnVlJQUT0/Pffv2WbCG6OhoV1fXli1bnj9/3iIFlJSUdO7c+cyZM1evXrXg\nrGpcXJyLi0tcXFxeXt6rr74aEBBgkanusLAwGxubrVu35uXlvfLKK5a6OEQ6fvy4q6urZa+SWr9+\nvfwPOS8vr9/jojtz/PTTT1qtNjY2Ni8v7/nnn7eyspKnE39vGzZskP/vr9Pp2rdvf/DgQUWFs6pp\naWne3t7ys4ODg5ub2/Xr1022zMzM9PLyqrKwcePG8oOdnZ05F9tmZmZWVFRs3LixRYsWf//73+Ws\nQ1pa2q5du+RV1U5OTuXl5ampqSa7My7eeMW71iC5u7vfvHmzysJbt26J2oyJEMLNzU1+kOfXzOzd\n5HZk70KIhg0byuNqOJcshHBycho8ePCOHTt27doVFBTUsGHD+oyAEKJLly4BAQGbN2/WL7nrvtd8\nxI1HIyMjw9PTUy7Ub1lyd3c3Hti0tDR3d3chRMuWLeXfDkdHx8aNGxve/1fbH8zw4cPnzJmzePFi\nLy+v4ODgKv/VVIXhuTl5T5X5w17Dj6FWNZgvNDRUlhEaGnpPNkgZfzBXr14dOHDgkiVLBg4caMEy\nxo8fn5mZ+e677w4aNKiysvL+F/DBBx+MGDGiS5cu979rQ717987Nze3du7dWq128ePHly5dr9Rf7\nXrG3t+/Xr9/o0aO1Wu2CBQsSEhIseC/Rpk2bxo0b16BBA0sVcPTo0Xnz5p04caKwsHDGjBnBwcGK\nJZ7ZEhAQEB4ePnnyZB8fH3mr8f05LbNx48YdO3ZoNBorK6tffvnl888///36qntUbdasWUpKivxc\nVFSUmZnp5uZmZWUlZ4OEEPopaA8PjxoSm/msra0nT548fvz44OBgOY/VrFkz/Uye5Ovra053Jlc0\ns4w+ffqkp6cbnv4+depU69atCwsLzR+Te6hnz57l5eU//PBDzc3Gjh27c+fO7du3jx07VtRvBKQP\nPvhgyZIl+glFk/te+735nxYtWly7dk1+1n+Q+vfvf+vWrfj4eP2S8vLyr776asiQIUKI9PR0ubCg\noOD27dv6vCvq9IN54403kpOTz549m5WVJS/zqJV7Muz1rMGkqKgoWUBUVNQ92SBl/JFcvHjxySef\nXLZs2YQJEyxdixBCjBs37saNG7m5ufe/661bty5YsECj0fj4+OTl5dXz6Tf3RHl5eWVlpUUimq+v\nr/4o1GeG5Z7Ys2fP8OHDLVhAXFxcUFBQYGCgk5PTW2+9df78eeNprPtjypQp165dy87OHjRo0EMP\nPXQfompaWtqpU6dKSkrkX86UlJTt27ffq5kUE2o1B2t4AcClS5ecnZ2///773NzcF198sWvXroqi\n3Lhxw9bW9sCBAxkZGT179pQnu1NTU7Va7b59+27fvv3BBx8MGzbM8H7w06dPy7PA1alyW1VZWVnH\njh1nzZqlKEpycrKLi8uePXvy8vLWrl3r6elZVlZmsjt9F3Ju3OSK5o/DO++84+fnFxcXV1RUdPz4\ncT8/v3feeadWY2I4AoafZXmVlZXmF6Moyrp169zd3aOjo/Py8rKzsz/99FMXF5fw8HDDHS8qKvLw\n8GjatGlhYWF1Q3fXjvQXAOj79fDwkKcATO67fo9MHnHDCwCMR+PSpUuNGjX697//ffPmzccff9zH\nx8ewkn/+859eXl67du3Kz8+/cOHCiBEjHnnkkdLS0mPHjgkhVqxYcfv27RdeeEGe2ddfAGDmD0Zf\n9pIlS0aMGJGTk5OZmfnoo49+/vnnJoelhicAmDPsNf8YzKwBfySWvQAgOzvb29v7yJEjlipA2rp1\nq5+f37lz5/Lz819//XWL32xu2QsAvv76a19f38TExNzc3BkzZgwYMMAiZWRlZbm4uKxZs6agoGD2\n7NmDBg2ySBmKouTk5Agh9DeeW0RsbKyrq+vhw4cLCws//vjjVq1aWeSqjNOnT7ds2fLnn3++ceNG\ncHDwu+++ex86XbRo0dixYw2X9OrVa8WKFWp8AsC2bdv8/PwcHByeeOKJq1evyoVLly51d3f39PRc\nsWKF/gkAO3fu9PPzc3R0fOKJJ9LS0uoTVRVFOXr0qLW19fHjxxVF+e677zp27Ojg4NCtW7dTp05V\n152+i4kTJ9rZ2Z0/f97kimbS6XQff/xx27Zt7e3tW7duvWTJEv0P1MwxqS6d6MurVT2KouzZs2fA\ngAFarbZhw4YDBw6UzzQx3HFFUcaPH294F20dRqBKVNXpdD179tQ/AcDkvss9qkNUVRRlzZo1ctze\neust/W9Jb/PmzV27dm3QoEGLFi1mz54tbwI9duxYt27dQkJCnJycgoODb968KRf6+fnVsNdVfjCK\nwYGYOHGiVqt1dnaePn16dWne+FpVIcSmTZvMHPa7/hjMqQF/JJaNqsZ3PRYUFFikkvfee8/Dw8PZ\n2Xno0KHJyckWqUHPslFVUZT33nuvefPmDRo0CA4OtmBEO3HiRLdu3RwdHQcMGHDt2jVLlfGf//zH\nsodDioiI8PHxcXJy6tevn+Fzge6zjz76yM3NrVGjRrNmzapPIjRfhw4doqOjDZcsX768c+fOxnfa\nxcbGmlxYq+40Cq/DgboVFBS88cYbQoiIiIg6rF5RUbFly5aVK1fKCVcAAPAA+dO9WBUPigsXLgQG\nBjo4OHh4eGRlZS1cuLBu24mIiJg5c+YLL7xwb8sDAAD3AbOqAAAAUClmVQEAAKBSGiGYVQUAAIAa\nMasKAAAAlSKqAgAAQKWIqgAAAFApoioAAABUysZ4kQWfXqXR/OZflirjt7eaUYbqyuAnqsKDQhn8\nRH9LdQeFMijjtyjDkErK0PvN31BmVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUA\nAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACo\nFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEV\nAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAA\nKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVU\nBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEpphFAsXQMAAABgArOqAAAAUCmiKgAAAFSK\nqAoAAACVIqoCAABApWwU7qoCAACAKjGrCgAAAJUiqgIAAECliKoAAABQKaIqAAAAVIqoCuCPbPny\n5RrznDlzxnj1KVOmyG8TEhJq6EVRlC+//DIkJMTLy6tBgwaNGjUKCAiYNWuW8Tbj4uLkBktKSoy3\nc+3atfbt22s0Gjc3t9OnT5vsa8SIERqNpn///jXv+PDhwzUaTWhoqBAiIyPDnBHYunWr8XaSkpLm\nz5/fvXt3Dw8POzs7Dw+PoUOHRkdH63Q6fZv6DHJSUtKbb74ZGBjo6upqa2vr5uY2YMCATz75JD8/\n37iYtLQ0k5u1srJycHBo1apVSEhIbGxszSMD4AGjAMAf17Jly8z8Y3j69Okq6+bm5jo4OMhvJ0+e\nXF0XeXl5vXv3NrlNKyursLAww8ZHjx6VXxUXF1fZzuXLl1u2bCmEaNGixYULF6rrbseOHUIIjUaT\nlJRUXZvr169bW1sLIeLi4hRFSU9PN2cEvv76a8ONlJWVhYWFaTQak4179eqVnp5en0GurKwMCwuz\nsbEx2dLV1XXv3r1V9uvatWvm9LJ06dLqRgbAA4eoCuDPpUePHkKIf/zjH3dtGRERIYQYPXq0jY2N\nvb19ZmamyWbjxo2T0WrNmjWpqallZWXZ2dknT558/vnnZXJauXKlvnF1UfXcuXPNmjUTQrRu3frK\nlSs1VFVRUdG8eXMhxPz586trs2DBAiFEhw4d5D/1UfXcuXN33WupsrJy8ODBQghra+sJEyYcOnQo\nPT39zp0758+ff/vtt52cnIQQAQEBBQUFJle/6yDrdLoxY8bIqoYMGbJr167MzMySkpLLly9HRES0\na9dOCGFlZbV69WrDtfRR9eeff66ytdzc3P3793fr1k2uWEOOB/BgIaoC+HMxP6o+8sgjQoi9e/eO\nGjVKCPHRRx8Zt0lPT5fzjkePHjX+9u233xZCNGvWrLKyUi4xGVVPnDjRpEkTIYS/v//169fvWthb\nb70lhPD29tbpdMbf6nQ6Hx8fIcSyZcv0RdY2qsqwa29vv23bNuNvDx061KBBAyHEvHnzTK5+10H+\n6KOPZKZcv3698bd37twZO3asLODs2bP65dVFVb2cnJxGjRoJIRYuXFjj/gF4YHCtKgCYcPbs2R9/\n/PGhhx4KCgp65plnhBCfffaZ4QWakpwBtbOzM3kNwKxZszQaTUZGRlJSUnUdHTlyJCgoKCcnp2vX\nrkeOHJEzpjWbNm2aRqNJSUkxeV3mgQMHrl69am9vP3ny5LtuyqSsrCwZVcPCwp566injBo899tgL\nL7wghIiKiqqsrKzt9vPz8z/88EMhxPz58+XVtFU4Ojpu2rQpICCgtLT01VdfNX/LjRs3DggIEEKk\npqbWtioA6kRUBQATPv/8cyHE+PHjbWxsgoOD3d3dr1y5snfv3irNvLy8hBBlZWXyEtIqmjZtKic+\n27Zta7KXvXv3PvnkkwUFBX369Dl48KCrq6s5tbVu3VreVrV+/Xrjb9euXSuEGD169EMPPWTO1ozF\nxMSUlJTY2dnVEBPffvvthISEq1evyotia7v9vLw8JyenV155pbo2dnZ27777rhDiwIEDZl5rK4TI\nyso6d+6cEMKcxA/ggUBUBYCqSktL//WvfwkhpkyZIoSwsbGZOHGiEGLVqlVVWnp5eYWEhAghnn76\n6YkTJ8bExGRnZ5vZS0xMzMiRI4uLi/v27fv999+7uLiYX+G0adPkFqrcKZ+VlfXNN98IIaZPn27+\n1qqIj48XQvTo0UOr1VbXxtXVtUePHnZ2dnXY/uHDh4UQvXr1cnZ2rqHZ0KFDHRwcdDrdvn37at5g\neXl5RkbG9u3b+/fvn5+fb2trO2HChDoUBkCFiKoAUNW2bdtycnL8/Py6d+8ul8jz1Hv27ElOTq7S\nOCoqavjw4RUVFdHR0WPGjHFzc/P39582bVp0dHReXl51XWzcuHHcuHFlZWVCiNTU1NLS0lpVGBIS\n0qRJk+Li4i1btlTZbFlZWdu2bR9//HHjtTp16lTdY6T0NzkJIVJSUoQQvr6+tSrJfFeuXBFC+Pn5\n1dzMwcFBTlob3/jv7+9vWLx8ilZISMhPP/1ka2u7du3a6qaxATxwiKoAUFVkZKT475Sq1KVLly5d\nuuh0us8++6xKY2dn5507d+7fv3/q1KlNmzZVFOXixYuRkZETJ0708PB45513iouLjbuYMWNGZWVl\ncHCwVqtNSUl57rnnalWh/lLUqKgo48rrM6UqhJABuuYpz/rIzc0VQpgziyyviLh58+ZdW2o0mtat\nW8+YMePMmTNTp06td40A1IKoCgC/kZycfPDgQSsrq0mTJhkulxOrkZGRMslVERQUFBUVlZGR8fPP\nP69du3bSpElubm7FxcULFy4cPnx4eXm58SqhoaE7d+789NNPhRDbt29fuXJlreqU1wDEx8f/8ssv\nckl8fPyFCxdsbW2ry2o1PAHA8Pn/7u7uQoicnJxa1WO+xo0bCyFMJvgqCgoKhBD6p9vq6Z8AUFRU\ntHnz5qZNm8qHaq1atapDhw6/R80ALIWoCgC/ERkZqSiKTqdr2bKl4VnmuXPnCiEyMzO//vrrGlb3\n8/ObNm3apk2b0tLSPvnkE1tb2wMHDmzYsKFKs9mzZ69bt87a2nrSpEnyQtjXXnvN5BuzqtOxY0f5\nTCj9xKq8oWrUqFEya9aZfBNBDU8tkEzmb3O0atVKCHHp0qW7bl/WUMOlCA4ODhMmTIiNjXVyclq4\ncOGcOXPqVhIA1SKqAsD/6HS6KqfUjRneXCXfg7pt2zbjZnZ2di+//PKzzz4rhDC+MWjx4sX6F0Gt\nWrXK29u7tLR07NixhYWF5lcrJ1Y3bdqk0+kKCgpkhq7n2X8hxKBBg4QQJ06cuH37dnVtkpOTXVxc\n+vTpc/bs2dpuX75c4NChQybfnqp38ODBoqIiIcRd3yLr7+8vY3p4eHh4eHht6wGgZkRVAPif77//\nPi0tzcbGJiMjw/gs+ebNm4UQ8fHxiYmJsn3Hjh2FELt27apug02bNhX/vfqzOi4uLps2bbKysrp8\n+fKLL75ofrXjx49v2LDh9evXDx8+HBMTc+fOHR8fn4EDB5q/BZOeeOIJrVZbWVm5dOnS6tqsWbOm\nuLj4xx9/9Pb2ru32n3rqKRcXl8LCQvl0VZMqKirkw6r69u1rzg1eTz/9tLzrf+7cufIJBgD+GIiq\nAPA/8nGqQ4YMkRGzipCQEHmjj35iVb4d4Isvvvjuu++M2+fk5MhT/z179qy53759+7755ptyUyaf\nlmpSw4YNx48fL4TYsmXLl19+Kf77dgAzV6+Ovb39/PnzhRBLly7duXOncYPdu3cvWbJECDFz5sxa\nPWNLcnBwkCF4yZIlxrepCSHKy8ufe+65hIQEe3v7Tz75xMzNrlixwtXVtbKycsaMGXW+OAGA6vwe\nr8ACANWq4Z2ft27dsrW1FUKYfJuoJJ+K7+TklJeXpyiKTqcbNmyYEMLKyio0NDQ2NjY7O7usrCwl\nJSUyMrJNmzZCiObNm+fm5srVTb5YVSovL5evsHd0dLxw4YKZu5OQkCCEaNy4sY2NjY2NzY0bN4zb\n1OHFquXl5Y8++qgQQqPRhIaGHjlyJDs7u7S0NDEx8bXXXpOj1KFDh8LCQpOrm/P2Wv3LtIKDg3fv\n3i3HLTU1NSoqSr5xSqPRrFq1ynCVu75Ydd26dbLBokWLzNxTACpHVAXw51JDipJTfa6urmVlZdWt\nrr/dfsWKFXJJYWGhfAuASW3atPnpp5/0q9cQVRVFuXz5spOTkxCiU6dOJhuY1KlTJ7nNUaNGmWxg\n5tueBg8ebLjWnTt3Ro4cWV3jPn363Lx5s7qSzImqiqIsWrTIxsbG5PZdXV13795dpf1do6qiKP36\n9RNCODg4yHfeAnjQcQEAAPw/+VDSv/71r3LW0KR27drJp+tHRETIJU5OTjExMfv3758+fbq/v3+T\nJk1sbW09PDwGDRq0atWq8+fPyzlCc/j6+srz3efOnZs9e7aZa8mbq8S9uKHKkKOj4zfffLN79+6J\nEyf6+vo6ODjY2Ng0a9Zs2LBhW7ZsOXLkSD2fMyCEePPNNy9evPjGG2907drV2dnZ2tra1dV1wIAB\ny5cv//XXX4ODg+uwzdWrV9vZ2RUXF8+cObOe5QFQA42iKJauAQAAADCBWVUAAACoFFEVAAAAKkVU\nBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAA\ngEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoR\nVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEA\nAKBSRFUAAACoFFEVAAAAKkVUBQAAgEoRVQEAAKBS/wcP+VT2Fam/uwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=910x165 at 0x7F658A8187F0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXyLesex5MXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}